{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65edb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f877bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57443e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319851a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FeedForward(5,7,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e32da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471808b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a6333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9a8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4421, -0.3274,  1.2366,  0.5329],\n",
       "        [-0.4948,  1.5908, -1.1065,  0.0105],\n",
       "        [-0.9105,  1.5961,  0.0977, -0.7834],\n",
       "        [ 1.6821, -0.8249, -0.6762, -0.1810],\n",
       "        [-0.2390, -1.3627,  0.1671,  1.4346]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,4)\n",
    "ln = LayerNorm(4)\n",
    "ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99d7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.qw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,hidden_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        ## B,T,C\n",
    "        B,T,C = x.shape\n",
    "        q = self.qw(x)\n",
    "        k = self.kw(x)\n",
    "        v = self.vw(x)\n",
    "        print(q.shape,k.shape,k.T.shape)\n",
    "        att = q @ k.permute(0,2,1)\n",
    "#         att = att.masked_fill(mask, value)\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04576096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88463ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = Attention(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46641e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 6]) torch.Size([5, 3, 6]) torch.Size([6, 3, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_39250/1591781602.py:15: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  print(q.shape,k.shape,k.T.shape)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f302b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()        \n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.qw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        \n",
    "    def forward(self,q,k,v,masked=False):\n",
    "        #### q ==> B,T,C\n",
    "        q = self.qw(q)\n",
    "        k = self.kw(k)\n",
    "        v = self.vw(v)\n",
    "        #### q ===> B,head_size,T,hidden_size\n",
    "        B,T,C = q.shape\n",
    "        q = q.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = k.shape\n",
    "        k = k.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = v.shape\n",
    "        v = v.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,head_size,T,hidden_size = q.shape\n",
    "        att = q @ k.permute(0,1,3,2) # B,head_size,T,T\n",
    "        if masked:\n",
    "            _,_,m,n = att.shape\n",
    "            mask = torch.ones(m,n)\n",
    "            mask = torch.tril(mask)\n",
    "            att = att.masked_fill(mask==0,float('-inf'))\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v  # B,head_size,T,hidden_size\n",
    "        v = v.permute(0,2,1,3) # B,T,head_size,hidden_size\n",
    "        v = v.reshape(B,T,self.head_size * self.hidden_size)\n",
    "        return v       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6b61340",
   "metadata": {},
   "outputs": [],
   "source": [
    "att1 = MultiHeadAttention(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad12462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "693c4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = torch.randn(1,1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72fcd95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0201,  0.3462, -0.8698,  0.4331],\n",
       "          [-0.5261, -0.5521, -0.5846, -0.2188]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35020e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " _,_,m,n = att.shape\n",
    "mask = torch.ones(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e999702",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e63ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b64e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = att.masked_fill(mask==0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0113c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5065, 0.4935, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(att,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df863faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f0df0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self,q,k,v):\n",
    "        x = q + self.mha(q,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.fd(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "608ecd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = EncoderBlock(4,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7bf7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "        self.mha2 = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.fd2 = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln3 = LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self,x,k,v):\n",
    "#         x,k0,v0 = self.mha.qkv(x) ### 需要masked\n",
    "        x = x + self.mha(x,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mha2(x,k,v) ### cross attention\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.fd2(x)\n",
    "        x = self.ln3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08347ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e50db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abcd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabaeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f847430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c379827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a08dec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.vocab_set = set()\n",
    "        for sentence in sentences:\n",
    "            self.vocab_set.update(sentence)\n",
    "        self.vocab_set = list(self.vocab_set)\n",
    "        self.vocab_set = ['<pad>','<bos>','<eos>'] + self.vocab_set\n",
    "        self.token2id = {c:i for i,c in enumerate(self.vocab_set)}\n",
    "        self.id2token = {i:c for c,i in self.token2id.items()}\n",
    "    \n",
    "    def convert_token_to_id(self,tokens):\n",
    "        return [self.token2id.get(t,'') for t in tokens]\n",
    "    \n",
    "    def convert_id_to_token(self,ids):\n",
    "        return [self.id2token.get(i,-1) for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9c5a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4171e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "df1abc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68ddc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self,n,input_dim,head_size,hidden_dim,output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "           [DecoderBlock(input_dim,head_size,hidden_dim)   for _ in range(n)]\n",
    "        )\n",
    "        self.output_embeddings = nn.Embedding(output_vocab_size,input_dim)\n",
    "        self.output_linear = nn.Linear(head_size * hidden_dim,output_vocab_size)\n",
    "        self.output_pos_embedding = nn.Embedding(1024,input_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,y):\n",
    "        B,T = y.shape\n",
    "        y = self.output_embeddings(y) ### B,T,C\n",
    "        y_pos = self.output_pos_embedding(torch.arange(T))\n",
    "        y = y + y_pos\n",
    "        for block in self.decoder_blocks:\n",
    "            y = block(y,y,y) ### B,head_size,T,hidden_size\n",
    "        logits = self.output_linear(y) # B,T,output_vocab_size\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdc3f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['你好，世界',\n",
    "             '好奇怪']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fc267d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "899ab5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>',\n",
       " 1: '<bos>',\n",
       " 2: '<eos>',\n",
       " 3: '好',\n",
       " 4: '世',\n",
       " 5: '，',\n",
       " 6: '怪',\n",
       " 7: '奇',\n",
       " 8: '你',\n",
       " 9: '界'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3aef35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "input_dim = 64\n",
    "head_size = 4\n",
    "hidden_dim = input_dim // head_size\n",
    "output_vocab_size = len(tokenizer.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "649cfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(n,input_dim,head_size,hidden_dim,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd59feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(gpt.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afacfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37e906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentences,tokenizer,max_length):\n",
    "    res = []\n",
    "    length = []\n",
    "    for sentence in sentences:\n",
    "        arr = tokenizer.convert_token_to_id(sentence) + tokenizer.convert_token_to_id(['<eos>'])\n",
    "        length.append(len(arr))\n",
    "        if len(arr) > max_length:\n",
    "            arr = arr[:max_length]\n",
    "        else:\n",
    "            arr = arr + tokenizer.convert_token_to_id(['<pad>']) * (max_length - len(arr))\n",
    "        res.append(arr)\n",
    "    return res,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8dcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03cceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,lengths = process(sentences,tokenizer,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c59d8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8c4e6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afa4a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5003b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc9f2d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3b90576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3761, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6796, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3990, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    y_inputs = y[:,:-1]\n",
    "    y_targets = y[:,1:]\n",
    "    logits = gpt(y_inputs)\n",
    "    B,T = y_targets.shape\n",
    "    # 计算损失\n",
    "#     loss = criterion(logits.reshape(B*T,-1), y_targets.reshape(B*T))\n",
    "    \n",
    "    \n",
    "    # 创建mask来标记有效位置\n",
    "    mask = torch.arange(T, device=y_targets.device)[None,:] < (batch_length-1)[:,None]  # shape: (B,T)\n",
    "    mask = mask.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "    # 只计算有效位置的loss\n",
    "    logits_flat = logits.reshape(-1, logits.size(-1))  # shape: (B*T,vocab_size) \n",
    "    targets_flat = y_targets.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "    # 方法1: 使用mask选择有效位置\n",
    "    valid_logits = logits_flat[mask]  # shape: (num_valid,vocab_size)\n",
    "    valid_targets = targets_flat[mask]  # shape: (num_valid)\n",
    "    loss = criterion(valid_logits, valid_targets)\n",
    "    print(loss)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d8c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,inputs,tokenizer):\n",
    "    ids = tokenizer.convert_token_to_id(inputs)\n",
    "    print(ids)\n",
    "    y = torch.LongTensor([ids])\n",
    "    print('yyyy shape',y.shape)\n",
    "    for _ in range(100):\n",
    "        logits = model(y)\n",
    "        ### logits B,T,vocab_size\n",
    "        logits = logits[:,-1,:]\n",
    "        ### logits B,T,vocab_size\n",
    "        predicts = logits.argmax(dim=-1,keepdim=True) # B,1\n",
    "        y = torch.cat((y,predicts),dim=-1)\n",
    "    print(y.shape)\n",
    "    for b in range(y.shape[0]):\n",
    "        for i in y[b]:\n",
    "            print(tokenizer.convert_id_to_token([int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "193c0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 5]\n",
      "yyyy shape torch.Size([1, 2])\n",
      "torch.Size([1, 102])\n",
      "['你']\n",
      "['，']\n",
      "['界']\n",
      "['世']\n",
      "['界']\n",
      "['<eos>']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['世']\n",
      "['界']\n",
      "['界']\n",
      "['世']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n",
      "['界']\n"
     ]
    }
   ],
   "source": [
    "predict(gpt,'你，',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de20524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
