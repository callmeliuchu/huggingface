{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4376c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f5dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc83f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fc740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667ba234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90999be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad94261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e3fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast,GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d79de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f7e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_image_token_processor_1 import PaliGemmaProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f624800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa43504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder_1 import PaliGemmaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf5d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b232726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d58176",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85cad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:dddd\n"
     ]
    }
   ],
   "source": [
    "logger.info('dddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bcd4760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m                     multi_modality.ipynb\r\n",
      "decoder_1.py                    simple_model_state_dict.pth\r\n",
      "final_data.json                 text_image_token_processor_1.py\r\n",
      "fintune.ipynb                   tokens.json\r\n",
      "gpt_from_scratch.ipynb          translate_from_scratch.ipynb\r\n",
      "hg_learn.ipynb                  utils.py\r\n",
      "inference.ipynb                 vision_model.ipynb\r\n",
      "\u001b[1m\u001b[36mmarian-finetuned-kde4-en-to-fr\u001b[m\u001b[m  vision_transformer_1.py\r\n",
      "mml_decoder.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c8b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                processor: PaliGemmaProcessor,\n",
    "                 split: str = 'train',\n",
    "                 max_length: int = 512,\n",
    "                 max_samples: int = None\n",
    "                ):\n",
    "        self.dataset = load_dataset('food101',split=split)\n",
    "        if max_samples:\n",
    "            self.dataset = self.dataset.select(range(max_samples))\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item['image']\n",
    "        text = f'this is a picture of {item[\"label\"]}'\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            text = [text],\n",
    "            images=[image],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids':inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'pixel_values':inputs['pixel_values'].squeeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47a8b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self,\n",
    "                model: PaliGemmaForConditionalGeneration,\n",
    "                 train_dataloader: DataLoader,\n",
    "                 val_dataloader: Optional[DataLoader],\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 device: str,\n",
    "                 gradient_accumulation_steps: int = 1,\n",
    "                 max_grad_norm: float = 1.0,\n",
    "                 use_amp: bool = True,\n",
    "                ):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.use_amp = use_amp\n",
    "        \n",
    "        self.scaler = GradScaler() if use_amp else None\n",
    "    \n",
    "    def train_epoch(self,epoch: int):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_dataloader,desc=f\"training epoch {epoch}\")\n",
    "        \n",
    "        for step, batch in enumerate(pbar):\n",
    "            batch = {k:v.to(self.device) for k,v in batch.items()}\n",
    "            \n",
    "            with autocast(enabled=self.use_amp):\n",
    "                outputs = self.model(\n",
    "                    input_ids=batch['input_ids'],\n",
    "                    pixel_values=batch['pixel_values'],\n",
    "                    attention_mask=batch['attention_mask']\n",
    "                )\n",
    "                \n",
    "                shift_logits = outputs['logits'][:,:-1,:].contiguous()\n",
    "                shift_labels = batch[\"input_ids\"][...,1:].contiguous()\n",
    "                \n",
    "                loss = torch.nn.functional.cross_entropy(\n",
    "                    shift_logits.view(-1,shift_logits.size(-1)),\n",
    "                    shift_labels.view(-1),\n",
    "                    ignore_index=-100\n",
    "                )\n",
    "                \n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "            \n",
    "            if self.use_amp:\n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                if self.use_amp:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self.model.parameters(),\n",
    "                    self.max_grad_norm\n",
    "                )\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / (step + 1)\n",
    "            pbar.set_postfix({'loss':avg_loss})\n",
    "        \n",
    "        return total_loss / len(self.train_dataloader)\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self):\n",
    "        if not self.val_dataloader:\n",
    "            return None\n",
    "        \n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(self.val_dataloader,desc='Evaluating'):\n",
    "            batch = {k:v.to(self.device) for k,v in batch.items()}\n",
    "            \n",
    "            outputs = self.model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                pixel_values=batch['pixel_values'],\n",
    "                attention_mask=batch['attention_mask']\n",
    "            )\n",
    "            \n",
    "            shift_logits = outputs['logits'][:,:-1,:].contiguous()\n",
    "            shift_labels = outputs['input_ids'][...,1:].continguous()\n",
    "            loss = torch.nn.functional.cross_entropy(\n",
    "                shift_logits.view(-1,shift_logits.size(-1)),\n",
    "                shift_labels.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_dataloader)\n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86209bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Training configuration\n",
    "    config = {\n",
    "        'model_path': \"/Users/liuchu/vision-launguage-model-from-scratch/paligemma-3b-pt-224\",\n",
    "        'train_json': \"data/train.json\",\n",
    "        'val_json': \"data/val.json\",\n",
    "        'image_dir': \"data/images/\",\n",
    "        'output_dir': \"trained_model/\",\n",
    "        'batch_size': 4,\n",
    "        'gradient_accumulation_steps': 4,\n",
    "        'learning_rate': 5e-5,\n",
    "        'weight_decay': 0.01,\n",
    "        'num_epochs': 1,\n",
    "        'use_amp': True,\n",
    "        'max_grad_norm': 1.0,\n",
    "    }\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, tokenizer = load_hf_model(config['model_path'],device)\n",
    "    processor = PaliGemmaProcessor(\n",
    "        tokenizer,\n",
    "        num_image_tokens=model.config.vision_config.num_image_tokens,\n",
    "        image_size=model.config.vision_config.image_size\n",
    "    )\n",
    "    \n",
    "    train_dataset = MultiModalDataset(\n",
    "        processor=processor,\n",
    "        split='train',\n",
    "        max_samples=10\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiModalDataset(\n",
    "        processor=processor,\n",
    "        split='validation',\n",
    "        max_samples=1\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    ) if val_dataset else None\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        use_amp=config['use_amp'],\n",
    "        max_grad_norm=config['max_grad_norm']\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        train_loss = trainer.train_epoch(epoch)\n",
    "        logger.info(f'Epoch {epoch} - Train loss: {train_loss:.4f}')\n",
    "        \n",
    "        if val_dataloader:\n",
    "            val_loss = trainer.evaluate()\n",
    "            logger.info(f'Epoch {epoch} - Val loss: {val_loss:.4f}')\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                model.save_pretrained(os.path.join(config['output_dir'], 'best_model'))\n",
    "            checkpoint_dir = os.path.join(config['output_dir'],\n",
    "                                                  f'checkpoint-{epoch}')\n",
    "            model.save_pretrained(checkpoint_dir)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d62f568a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/datasets/food101/revision/e06acf2a88084f04bce4d4a525165d68e0a36c38 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x37f69c2b0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: d9778e83-3942-48d6-b645-c6d053c4872c)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 27\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m load_hf_model(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m],device)\n\u001b[1;32m     21\u001b[0m processor \u001b[38;5;241m=\u001b[39m PaliGemmaProcessor(\n\u001b[1;32m     22\u001b[0m     tokenizer,\n\u001b[1;32m     23\u001b[0m     num_image_tokens\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_config\u001b[38;5;241m.\u001b[39mnum_image_tokens,\n\u001b[1;32m     24\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvision_config\u001b[38;5;241m.\u001b[39mimage_size\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMultiModalDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m MultiModalDataset(\n\u001b[1;32m     34\u001b[0m     processor\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[1;32m     35\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m     max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     40\u001b[0m     train_dataset,\n\u001b[1;32m     41\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     45\u001b[0m )\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mMultiModalDataset.__init__\u001b[0;34m(self, processor, split, max_length, max_samples)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m             processor: PaliGemmaProcessor,\n\u001b[1;32m      5\u001b[0m              split: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m              max_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      7\u001b[0m              max_samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m             ):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfood101\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_samples:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(max_samples))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2125\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2126\u001b[0m )\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2129\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/load.py:1849\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1848\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1849\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/load.py:1731\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1726\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1727\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1728\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1729\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1730\u001b[0m                     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1731\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trust_remote_code:\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1734\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1735\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/load.py:1696\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1698\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/load.py:1026\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mdownload_desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading standalone yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m     standalone_yaml_path \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_dataset_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREPOYAML_FILENAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(standalone_yaml_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1031\u001b[0m         standalone_yaml_data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/datasets/utils/file_utils.py:180\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Download files from Hugging Face.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Note: no need to check for https://huggingface.co file URLs since _prepare_path_and_storage_options\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# prepares Hugging Face HTTP URLs as hf:// paths already\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m url_or_filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    178\u001b[0m     resolved_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfFileSystem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m--> 180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         output_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfApi(\n\u001b[1;32m    183\u001b[0m             endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT,\n\u001b[1;32m    184\u001b[0m             token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m    195\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py:175\u001b[0m, in \u001b[0;36mresolve_path\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    172\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# can't list repositories at root\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to repositories lists is not implemented.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mREPO_TYPES_URL_PREFIXES\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# can't list repositories at the repository type level\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py:121\u001b[0m, in \u001b[0;36m_repo_and_revision_exist\u001b[0;34m(self, repo_type, repo_id, revision)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Maps (repo_type, repo_id, revision) to a 2-tuple with:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#  * the 1st element indicating whether the repositoy and the revision exist\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#  * the 2nd element being the exception raised if the repository or revision doesn't exist\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo_and_revision_exists_cache: Dict[\n\u001b[1;32m    117\u001b[0m         Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mstr\u001b[39m]], Tuple[\u001b[38;5;28mbool\u001b[39m, Optional[\u001b[38;5;167;01mException\u001b[39;00m]]\n\u001b[1;32m    118\u001b[0m     ] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repo_and_revision_exist\u001b[39m(\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28mself\u001b[39m, repo_type: \u001b[38;5;28mstr\u001b[39m, repo_id: \u001b[38;5;28mstr\u001b[39m, revision: Optional[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbool\u001b[39m, Optional[\u001b[38;5;167;01mException\u001b[39;00m]]:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (repo_type, repo_id, revision) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo_and_revision_exists_cache:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2756\u001b[0m, in \u001b[0;36mrepo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrepo_exists\u001b[39m(\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2749\u001b[0m     token: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2750\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;124;03m    Checks if a repository exists on the Hugging Face Hub.\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \n\u001b[1;32m   2754\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[0;32m-> 2756\u001b[0m \u001b[38;5;124;03m            A namespace (user or an organization) and a repo name separated\u001b[39;00m\n\u001b[1;32m   2757\u001b[0m \u001b[38;5;124;03m            by a `/`.\u001b[39;00m\n\u001b[1;32m   2758\u001b[0m \u001b[38;5;124;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;124;03m            Set to `\"dataset\"` or `\"space\"` if getting repository info from a dataset or a space,\u001b[39;00m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;124;03m            `None` or `\"model\"` if getting repository info from a model. Default is `None`.\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;124;03m        token (Union[bool, str, None], optional):\u001b[39;00m\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;124;03m            A valid user access token (string). Defaults to the locally saved\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[38;5;124;03m            token, which is the recommended method for authentication (see\u001b[39;00m\n\u001b[1;32m   2764\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/huggingface_hub/quick-start#authentication).\u001b[39;00m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;124;03m            To disable authentication, pass `False`.\u001b[39;00m\n\u001b[1;32m   2766\u001b[0m \n\u001b[1;32m   2767\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;124;03m        True if the repository exists, False otherwise.\u001b[39;00m\n\u001b[1;32m   2769\u001b[0m \n\u001b[1;32m   2770\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;124;03m        ```py\u001b[39;00m\n\u001b[1;32m   2772\u001b[0m \u001b[38;5;124;03m        >>> from huggingface_hub import repo_exists\u001b[39;00m\n\u001b[1;32m   2773\u001b[0m \u001b[38;5;124;03m        >>> repo_exists(\"google/gemma-7b\")\u001b[39;00m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;124;03m        True\u001b[39;00m\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;124;03m        >>> repo_exists(\"google/not-a-repo\")\u001b[39;00m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;124;03m        False\u001b[39;00m\n\u001b[1;32m   2777\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2779\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2780\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo_info(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, token\u001b[38;5;241m=\u001b[39mtoken)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2613\u001b[0m, in \u001b[0;36mdataset_info\u001b[0;34m(self, repo_id, revision, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mspace_info\u001b[39m(\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2605\u001b[0m     token: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2606\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SpaceInfo:\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;124;03m    Get info on one specific Space on huggingface.co.\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \n\u001b[1;32m   2610\u001b[0m \u001b[38;5;124;03m    Space can be private if you pass an acceptable token.\u001b[39;00m\n\u001b[1;32m   2611\u001b[0m \n\u001b[1;32m   2612\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m-> 2613\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;124;03m            A namespace (user or an organization) and a repo name separated\u001b[39;00m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;124;03m            by a `/`.\u001b[39;00m\n\u001b[1;32m   2616\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   2617\u001b[0m \u001b[38;5;124;03m            The revision of the space repository from which to get the\u001b[39;00m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;124;03m            information.\u001b[39;00m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;124;03m        timeout (`float`, *optional*):\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;124;03m            Whether to set a timeout for the request to the Hub.\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;124;03m        files_metadata (`bool`, *optional*):\u001b[39;00m\n\u001b[1;32m   2622\u001b[0m \u001b[38;5;124;03m            Whether or not to retrieve metadata for files in the repository\u001b[39;00m\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;124;03m            (size, LFS metadata, etc). Defaults to `False`.\u001b[39;00m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;124;03m        expand (`List[ExpandSpaceProperty_T]`, *optional*):\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;124;03m            List properties to return in the response. When used, only the properties in the list will be returned.\u001b[39;00m\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;124;03m            This parameter cannot be used if `full` is passed.\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;124;03m            Possible values are `\"author\"`, `\"cardData\"`, `\"createdAt\"`, `\"datasets\"`, `\"disabled\"`, `\"lastModified\"`, `\"likes\"`, `\"models\"`, `\"private\"`, `\"runtime\"`, `\"sdk\"`, `\"siblings\"`, `\"sha\"`, `\"subdomain\"`, `\"tags\"`, `\"trendingScore\"`, `\"usedStorage\"` and `\"resourceGroup\"`.\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;124;03m        token (Union[bool, str, None], optional):\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;124;03m            A valid user access token (string). Defaults to the locally saved\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m \u001b[38;5;124;03m            token, which is the recommended method for authentication (see\u001b[39;00m\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/huggingface_hub/quick-start#authentication).\u001b[39;00m\n\u001b[1;32m   2632\u001b[0m \u001b[38;5;124;03m            To disable authentication, pass `False`.\u001b[39;00m\n\u001b[1;32m   2633\u001b[0m \n\u001b[1;32m   2634\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;124;03m        [`~hf_api.SpaceInfo`]: The space repository information.\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \n\u001b[1;32m   2637\u001b[0m \u001b[38;5;124;03m    <Tip>\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \n\u001b[1;32m   2639\u001b[0m \u001b[38;5;124;03m    Raises the following errors:\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m \n\u001b[1;32m   2641\u001b[0m \u001b[38;5;124;03m        - [`~utils.RepositoryNotFoundError`]\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m \u001b[38;5;124;03m          If the repository to download from cannot be found. This may be because it doesn't exist,\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;124;03m          or because it is set to `private` and you do not have access.\u001b[39;00m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;124;03m        - [`~utils.RevisionNotFoundError`]\u001b[39;00m\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;124;03m          If the revision to download from cannot be found.\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m \n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m    </Tip>\u001b[39;00m\n\u001b[1;32m   2648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expand \u001b[38;5;129;01mand\u001b[39;00m files_metadata:\n\u001b[1;32m   2650\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`expand` cannot be used if `files_metadata` is set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:93\u001b[0m, in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: PreparedRequest, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_DEBUG:\n\u001b[1;32m     94\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/datasets/food101/revision/e06acf2a88084f04bce4d4a525165d68e0a36c38 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x37f69c2b0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: d9778e83-3942-48d6-b645-c6d053c4872c)')"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae4327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
