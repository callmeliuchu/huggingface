{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65edb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f877bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57443e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319851a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FeedForward(5,7,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e32da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471808b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a6333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9a8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3281,  0.9805, -1.4920,  0.8396],\n",
       "        [ 1.4041, -1.4004,  0.1815, -0.1853],\n",
       "        [ 1.0092,  0.7120, -0.1560, -1.5653],\n",
       "        [-1.3875,  0.3816,  1.3465, -0.3405],\n",
       "        [ 0.4233,  0.6256,  0.6754, -1.7243]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,4)\n",
    "ln = LayerNorm(4)\n",
    "ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99d7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.qw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,hidden_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        ## B,T,C\n",
    "        B,T,C = x.shape\n",
    "        q = self.qw(x)\n",
    "        k = self.kw(x)\n",
    "        v = self.vw(x)\n",
    "        print(q.shape,k.shape,k.T.shape)\n",
    "        att = q @ k.permute(0,2,1)\n",
    "#         att = att.masked_fill(mask, value)\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04576096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88463ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = Attention(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46641e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 6]) torch.Size([5, 3, 6]) torch.Size([6, 3, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_3298/1591781602.py:15: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  print(q.shape,k.shape,k.T.shape)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f302b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()        \n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.qw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        \n",
    "    def forward(self,q,k,v,masked=False):\n",
    "        #### q ==> B,T,C\n",
    "        q = self.qw(q)\n",
    "        k = self.kw(k)\n",
    "        v = self.vw(v)\n",
    "        #### q ===> B,head_size,T,hidden_size\n",
    "        B,T,C = q.shape\n",
    "        q = q.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = k.shape\n",
    "        k = k.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = v.shape\n",
    "        v = v.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,head_size,T,hidden_size = q.shape\n",
    "        att = q @ k.permute(0,1,3,2) # B,head_size,T,T\n",
    "        if masked:\n",
    "            _,_,m,n = att.shape\n",
    "            mask = torch.ones(m,n)\n",
    "            mask = torch.tril(mask)\n",
    "            att = att.masked_fill(mask==0,float('-inf'))\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v  # B,head_size,T,hidden_size\n",
    "        v = v.permute(0,2,1,3) # B,T,head_size,hidden_size\n",
    "        v = v.reshape(B,T,self.head_size * self.hidden_size)\n",
    "        return v       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b61340",
   "metadata": {},
   "outputs": [],
   "source": [
    "att1 = MultiHeadAttention(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad12462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "693c4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = torch.randn(1,1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72fcd95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1281, -0.5120, -0.9899, -1.0107],\n",
       "          [-0.7422,  1.2215, -0.4566, -0.5804]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35020e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " _,_,m,n = att.shape\n",
    "mask = torch.ones(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e999702",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e63ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = att.masked_fill(mask==0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0113c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1231, 0.8769, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(att,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df863faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0df0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self,q,k,v):\n",
    "        x = q + self.mha(q,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.fd(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "608ecd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = EncoderBlock(4,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8d870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7bf7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "        self.mha2 = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.fd2 = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln3 = LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self,x,k,v):\n",
    "#         x,k0,v0 = self.mha.qkv(x) ### 需要masked\n",
    "        x = x + self.mha(x,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mha2(x,k,v) ### cross attention\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.fd2(x)\n",
    "        x = self.ln3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08347ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e50db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abcd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabaeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f847430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c379827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a08dec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.vocab_set = set()\n",
    "        for sentence in sentences:\n",
    "            self.vocab_set.update(sentence)\n",
    "        self.vocab_set = list(self.vocab_set)\n",
    "        self.vocab_set = ['<pad>','<bos>','<eos>'] + self.vocab_set\n",
    "        self.token2id = {c:i for i,c in enumerate(self.vocab_set)}\n",
    "        self.id2token = {i:c for c,i in self.token2id.items()}\n",
    "    \n",
    "    def convert_token_to_id(self,tokens):\n",
    "        return [self.token2id.get(t,'') for t in tokens]\n",
    "    \n",
    "    def convert_id_to_token(self,ids):\n",
    "        return [self.id2token.get(i,-1) for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9c5a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4171e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df1abc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68ddc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self,n,input_dim,head_size,hidden_dim,output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "           [DecoderBlock(input_dim,head_size,hidden_dim)   for _ in range(n)]\n",
    "        )\n",
    "        self.output_embeddings = nn.Embedding(output_vocab_size,input_dim)\n",
    "        self.output_linear = nn.Linear(head_size * hidden_dim,output_vocab_size)\n",
    "        self.output_pos_embedding = nn.Embedding(1024,input_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,y):\n",
    "        B,T = y.shape\n",
    "        y = self.output_embeddings(y) ### B,T,C\n",
    "        y_pos = self.output_pos_embedding(torch.arange(T).to(y.device))\n",
    "        y = y + y_pos\n",
    "        for block in self.decoder_blocks:\n",
    "            y = block(y,y,y) ### B,head_size,T,hidden_size\n",
    "        logits = self.output_linear(y) # B,T,output_vocab_size\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdc3f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = ['你好，世界',\n",
    "#              '好奇怪']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fc267d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "899ab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3aef35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# input_dim = 64\n",
    "# head_size = 4\n",
    "# hidden_dim = input_dim // head_size\n",
    "# output_vocab_size = len(tokenizer.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "649cfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt = GPT(n,input_dim,head_size,hidden_dim,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd59feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = AdamW(gpt.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afacfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37e906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(sentences,tokenizer,max_length):\n",
    "#     res = []\n",
    "#     length = []\n",
    "#     for sentence in sentences:\n",
    "#         arr = tokenizer.convert_token_to_id(sentence) + tokenizer.convert_token_to_id(['<eos>'])\n",
    "#         length.append(len(arr))\n",
    "#         if len(arr) > max_length:\n",
    "#             arr = arr[:max_length]\n",
    "#         else:\n",
    "#             arr = arr + tokenizer.convert_token_to_id(['<pad>']) * (max_length - len(arr))\n",
    "#         res.append(arr)\n",
    "#     return res,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8dcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03cceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y,lengths = process(sentences,tokenizer,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c59d8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8c4e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afa4a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_length = torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5003b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc9f2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3b90576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(1000):\n",
    "#     y_inputs = y[:,:-1]\n",
    "#     y_targets = y[:,1:]\n",
    "#     logits = gpt(y_inputs)\n",
    "#     B,T = y_targets.shape\n",
    "#     # 计算损失\n",
    "# #     loss = criterion(logits.reshape(B*T,-1), y_targets.reshape(B*T))\n",
    "    \n",
    "    \n",
    "#     # 创建mask来标记有效位置\n",
    "#     mask = torch.arange(T, device=y_targets.device)[None,:] < (batch_length-1)[:,None]  # shape: (B,T)\n",
    "#     mask = mask.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "#     # 只计算有效位置的loss\n",
    "#     logits_flat = logits.reshape(-1, logits.size(-1))  # shape: (B*T,vocab_size) \n",
    "#     targets_flat = y_targets.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "#     # 方法1: 使用mask选择有效位置\n",
    "#     valid_logits = logits_flat[mask]  # shape: (num_valid,vocab_size)\n",
    "#     valid_targets = targets_flat[mask]  # shape: (num_valid)\n",
    "#     loss = criterion(valid_logits, valid_targets)\n",
    "#     print(loss)\n",
    "    \n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d8c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model,inputs,tokenizer):\n",
    "#     ids = tokenizer.convert_token_to_id(inputs)\n",
    "#     print(ids)\n",
    "#     y = torch.LongTensor([ids])\n",
    "#     print('yyyy shape',y.shape)\n",
    "#     for _ in range(100):\n",
    "#         logits = model(y)\n",
    "#         ### logits B,T,vocab_size\n",
    "#         logits = logits[:,-1,:]\n",
    "#         ### logits B,T,vocab_size\n",
    "#         predicts = logits.argmax(dim=-1,keepdim=True) # B,1\n",
    "#         y = torch.cat((y,predicts),dim=-1)\n",
    "#     print(y.shape)\n",
    "#     for b in range(y.shape[0]):\n",
    "#         for i in y[b]:\n",
    "#             print(tokenizer.convert_id_to_token([int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "193c0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(gpt,'你',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4de20524",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 解析本地抓取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72fca42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# 初始化 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# 编码文本\n",
    "text = \"你好，世界！\"\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "# 解码 token\n",
    "decoded_text = tokenizer.decode(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dcb04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [19526, 254, 25001, 121, 171, 120, 234, 10310, 244, 45911, 234, 171, 120, 223] <class 'list'>\n",
      "Decoded Text: 你好，世界！\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "print(f\"Tokens: {tokens}\",type(tokens))\n",
    "print(f\"Decoded Text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e04b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd31fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_data.json','r') as f:\n",
    "    law_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de011b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4501"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(law_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc097e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_raw_content(data):\n",
    "    ret = []\n",
    "    for k,v in data.items():\n",
    "        if 'content' in v:\n",
    "            ret.append(v['content'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "679901f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contents = get_all_raw_content(law_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50ae5f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022年12月30日, 中国证券投资基金业协会（“基金业协会”）发布通知, 就《私募投资基金登记备案办法（征求意见稿）草案/征求意见稿》及配套指引公开征求意见。基金业协会先后召开多次研讨会, 就各方反馈意见进行讨论评估, 认真听取业内各界的意见和建议。时隔两个多月, 基金业协会在认真研究并吸收采纳了各方面反馈的意见建议基础上, 于2023年2月24日正式发布了《私募投资基金登记备案办法》(“《私募登记备案办法》”)及配套指引。《私募登记备案办法》及其配套指引旨在对私募基金管理人登记和私募基金备案的标准和流程等重要问题进行修订完善, 在基础自律规则层面做出完整和集中的规定。《私募登记备案办法》对私募基金备案及业务规范进行了系统规定和细化更新, 从募、投、管、退等关键环节强化行业合规运作要求, 后续基金业协会将针对私募基金备案出台指引, 对相关规则要求进一步细化明确。本文结合现行规定及《私募登记备案办法》与《私募投资基金登记备案办法（征求意见稿）草案/征求意见稿》(“《征求意见稿草案/征求意见稿》”)的异同, 就《私募登记备案办法》对私募证券投资基金的主要影响进行简要介绍。为免疑义, 除非另有说明, 本文提及私募基金均指私募证券投资基金。一、增加基金文件必备要素《私募登记备案办法》第二十八条、第二十九条对现行规定中募集推介材料、风险揭示书以及基金合同的必备要素进行了梳理和重申, 其中, 对于风险揭示书及基金合同的必备要素, 《私募登记备案办法》在现行规定基础上有如下新变化。1. 基金合同《私募登记备案办法》第二十九条保留了《征求意见稿草案/征求意见稿》中相关表述, 在现行规定基础上, 进一步明确和细化了基金合同关于关联交易机制及私募基金管理人实际不能履职情况下的退出安排要求。基金合同中关联交易条款应当包含《私募登记备案办法》第三十八条规定的关联交易识别认定、交易决策、对价确定、信息披露和回避等机制。此外, 基金合同中应当明确私募基金管理人因失联、注销私募基金管理人登记、破产等原因无法履行或者怠于履行管理职责等情况时的处理机制。《私募登记备案办法》第五十八条为前述情形引入市场化退出机制, 即私募基金因管理人失联、注销私募基金管理人登记或出现重大风险等情形无法履职或怠于履职导致无法正常退出的, 管理人、托管人、份额持有人大会、或一定比例的投资者, 可以按照基金合同约定成立专项机构或委托会计师事务所、律师事务所等中介机构, 妥善处置基金财产、保护投资者合法权益并行使相关职权。采用该种退出方式的应当及时向基金业协会报送相关情况。2. 风险揭示书除现行规则要求进行特别提示的特殊风险外, 《私募登记备案办法》第二十八条新增了以下特殊风险披露事项:(1) 基金财产在境外进行投资;(2) 私募基金存在分级安排或者其他复杂结构, 或者涉及重大无先例事项;(3) 私募基金管理人的控制股东、实际控制人、普通合伙人发生变更, 尚未在基金业协会完成变更手续; 或者(4) 其他重大投资风险或者利益冲突风险。其中, 对于第(1)项, 2022年6月基金业协会发布的《私募证券投资基金备案关注要点》中仅要求私募基金“主要投向境外投资标的”时应当在特殊风险揭示部分进行风险披露, 而《私募登记备案办法》则规定无论境外标的投资比例大小, 只要进行境外投资均应当进行特别风险提示。此外, 相较于征求意见稿草案/征求意见稿, 《私募登记备案办法》第二十八条进一步细化了私募基金投向单一标的、未进行组合投资的风险披露要求, 即私募基金管理人应当对投资标的的基本情况、投资架构、因未进行组合投资而可能受到的损失、纠纷解决机制等进行书面揭示, 并由投资者签署确认。二、明确基金初始募集规模相较于《征求意见稿草案/征求意见稿》, 《私募登记备案办法》第三十三条对私募基金的初始实缴募集资金调整如下:由上可知, 《私募登记备案办法》正式施行后, 私募证券基金在募集期内应达到1000万元人民币的募集规模方可成功备案。此外, 相较于《征求意见稿草案/征求意见稿》, 《私募登记备案办法》对于投向单一标的的私募基金新增了2000万元的初始募集规模要求。举例而言, 对于采用母子结构的子基金（投资单一母基金）应当满足此项标准。此外, 现有QDLP基金产品, 大多采取联接基金结构（投资于单一境外母基金）, QDLP基金的初始募集规模理论上也应适用2000万元的标准, 除非监管部门或基金业协会对于QDLP基金另有不同规定。三、私募基金的持续报告义务1. 备案信息变更相较于《征求意见稿草案/征求意见稿》, 《私募登记备案办法》第五十五条适当放宽了私募基金管理人履行私募基金变更手续的时间要求, 即私募基金发生《私募登记备案办法》第五十五条所列变更后, 私募基金管理人向基金业协会履行变更手续的时限由变更之日起5个工作日延长至10个工作日。2. 重大事项报告《私募登记备案办法》第六十二条规定了需要向基金业协会报告的私募基金重大事项, 该等事项与《私募投资基金备案须知（2019年版）》（“《备案须知》”）第（二十六）条中需要报送的私募基金重大事项存在部分重合。在报告时限上, 对于相同事项, 《备案须知》要求5个工作日内进行报送, 《私募登记备案办法》要求10个工作日内进行报送。对于该类事项, 我们倾向于认为应采用“新法优于旧法”原则按10个工作日报送。此外, 《私募登记备案办法》第六十二条在《征求意见稿草案/征求意见稿》的基础上, 明确了私募基金在触发巨额赎回且不能满足赎回要求时, 方需向基金业协会报告。《私募登记备案办法》出台前, 《征求意见稿草案/征求意见稿》以及现行规定要求“私募基金触发巨额赎回”需要向基金业协会报告。对于巨额赎回触发报告义务的标准, 实践中曾存在不同观点。有观点认为, 当期赎回总份额达到巨额赎回标准, 无论私募基金管理人是否决定接受全部赎回申请, 均需要向基金业协会报告; 有观点认为, 当期赎回总份额达到巨额赎回标准且私募基金管理人决定适用巨额赎回条款, 对当期赎回申请采用部分赎回或延期赎回时, 才需要向基金业协会报告。基金业协会在资产管理业务综合报送平台上传的《重大事项报告说明》中, 将“巨额赎回”定义为“私募基金触发合同约定的巨额赎回条件, 且私募基金无法满足全部赎回申请的”情形, 对巨额赎回触发报告义务的标准予以明确;《私募登记备案办法》则正式在规则层面重申此项标准。3. 私募基金清算报送《私募投资基金管理人登记和基金备案办法（试行）》第二十三条规定, 私募基金发生清算应当在5个工作日内向基金业协会报送。《征求意见稿草案/征求意见稿》要求私募基金在开始清算及清算完成之日后的5个工作日内应当向基金业协会报送清算承诺函、清算公告等信息。《私募登记备案办法》第五十七条对私募基金清算报送流程及时限予以调整, 本条规定“自私募基金清算完成之日起10个工作日内向协会报送清算报告等信息。一定期限内无法完成清算的, 还应当自清算开始之日起10个工作日内向协会报送清算承诺函、清算公告等信息。”对于底层流动性较好的私募证券基金, 清算开始至清算完成的时间较短, 仅要求该类基金在清算完成后的10个工作日内履行报送义务。对于持有停牌股票等流动性较差资产的、可能涉及二次清算的私募基金, 应当分别在清算开始之日以及清算完成之日起的10个工作日内向基金业协会报送清算相关信息。4. 私募基金年度财务报告对于基金的年度财务报告审计要求, 《征求意见稿草案/征求意见稿》与《私募登记备案办法》出台前的现行规定保持一致, 即仅私募股权基金年度财务报告需经会计师事务所审计。《私募登记备案办法》在前述基础上, 进一步补充要求, 基金规模超过一定金额、投资者超过一定人数的私募基金, 其年度财务报告应当经中国证监会备案的会计师事务所审计。早在2022年8月, 基金业协会针对资产管理规模达到一定标准的私募基金管理人定向发送了《关于试运行“规模以上证券类管理人运作报表”的通知》, 要求该类私募基金管理人每月报送规模以上证券类管理人运作报表。结合本条, 我们理解, 对于规模较大、涉及投资者人数较多的私募基金管理人及私募基金, 未来可能需要遵守更高标准的信息披露及监管报送要求, 这也是基金业协会差异化管理监管理念的体现。四、明确审慎备案的标准和处理措施《私募登记备案办法》第四十四条在原《征求意见稿草案/征求意见稿》的基础上, 对于审慎备案的情形做了较大调整, 将私募基金投资者主要系自然人且基金投向单一标的、基金财产主要在境外投资、私募基金管理人最近2年每季度末管理规模均低于500万元等具体情形删除, 仅保留概括性规定, 即“私募基金管理人存在较大风险隐患, 私募基金涉及重大无先例事项, 或者存在结构复杂、投资标的类型特殊等情形的”, 基金业协会可以采取审慎备案相关处理措施。相较于《征求意见稿草案/征求意见稿》, 《私募登记备案办法》对于基金业协会针对审慎备案可以采取的相关处理措施基本保持不变。基金业协会可以视情况对管理人拟备案的私募基金采取下列措施: 提高投资者要求、提高基金规模要求、要求基金托管、要求托管人出具尽调报告或者配合询问、加强信息披露、提示特别风险、额度管理、限制关联交易、要求管理人出具内部合规意见、提交法律意见书或财务报告等。另外, 对于资本金、人员配备、投资管理能力、风控水平、内控制度、场所设施等与业务方向、管理规模等不匹配的管理人, 基金业协会亦可在其提交新基金备案时采取前述审慎备案措施。五、统一规定不予备案和暂停备案情形1. 不予备案《私募登记备案办法》对于私募基金不予备案的情形与原《征求意见稿草案/征求意见稿》基本一致。《私募登记备案办法》第四十一条整合了《关于加强私募投资基金监管的若干规定》和《备案须知》中违反私募基金投资禁止性规定、不符合“基金”本质的情形, 统一规定了不予办理私募基金备案的情形。该条第一款第(九)项设置了兜底条款, 认可其他现行规则中不予备案的情形, 如《私募投资基金募集行为管理办法》中规定了在管理人委托无基金销售资格的机构募集基金、募集机构未依法设置履行冷静期、回访确认等情形下, 基金业协会可以视情况不予备案私募基金。2. 暂停备案《私募登记备案办法》第四十二条吸收了《备案须知》第（二十九）条“紧急情况暂停备案”的大部分情形, 并在其基础上将私募基金暂停备案的情形进行了拓展。衔接《备案须知》等现行规定, 《私募登记备案办法》规定, 在私募基金管理人及其控股股东、实际控制人、普通合伙人、主要出资人自身资信情况出现重大问题或经营情况存在重大风险时, 基金业协会将暂停办理其私募基金备案, 例如: (1)《私募登记备案办法》第二十四条规定的私募基金管理人及其控股股东、实际控制人、普通合伙人、主要出资人因涉嫌违法违规被立案调查, 出现可能影响正常经营的重大诉讼、仲裁等法律风险, 出现重大内部纠纷, 出现重大负面舆情等情形; (2)私募基金管理人被列为严重失信人或者被纳入失信被执行人名单; (3)私募基金管理人及其控股股东、实际控制人、普通合伙人、关联私募基金管理人出现可能危害市场秩序或者损害投资者利益的重大经营风险或者其他风险; (4)因涉嫌违法违规、侵害投资者合法权益等多次收到投诉且未向基金业协会和投资者作出合理说明; (5)拒绝、妨碍、不配合监管部门检查、调查, 不配合行政监管或自律管理且情节严重; (6)中国证监会及其派出机构建议基金业协会暂停备案的。《私募登记备案办法》进一步规定, 若存在(1)未按规定向基金业协会报送信息, 或者报送的信息存在虚假记载、误导性陈述或者重大遗漏; (2)登记备案信息发生变更, 未按规定及时向基金业协会履行变更手续, 存在未及时改正等严重情形; 或者(3)办理登记备案业务时的相关承诺事项未履行或者未完全履行等情形, 亦可能被暂停备案。由此可知, 《私募登记备案办法》下, 若私募基金管理人未按规定履行日常报送义务, 即使未发生重大合规风险或存在重大经营问题, 也可能触发暂停备案。六、其他值得关注事项1. 投资者受益所有人的报送义务《私募登记备案办法》第三十九条第(七)项在《征求意见稿草案/征求意见稿》的基础上, 进一步要求私募基金管理人在私募基金备案时应当提交投资者的受益所有人相关信息。这是私募基金相关监管规则中首次提及私募基金投资者受益所有人报送要求。尚不明确投资者受益所有人采集和报送标准是否直接适用人行相关反洗钱规定, 随着配合《私募登记备案办法》的资产管理业务综合报送平台系统升级, 相关标准可能会逐渐清晰。此外, 代销模式下, 私募基金管理人和销售机构如何配合报送投资者受益所有人信息等问题, 尚待进一步观察。2. 引入重大无先例事项相较于《征求意见稿草案/征求意见稿》, 《私募登记备案办法》在第二十八条特殊风险揭示以及第四十四条审慎备案处均引入了重大无先例事项概念, 对从事创新业务的私募基金进行差异化监管。若私募基金拟投资于全新投资品种或涉及创新投资结构, 基金业协会可能基于个案原则, 对于此类私募基金采取审慎备案措施, 强化风险揭示要求。3. 《私募登记备案办法》的新老划断根据基金业协会发布的《关于发布<私募投资基金登记备案办法>的公告》, 《私募登记备案办法》自2023年5月1日起施行。对于2023年5月1日前已提交的登记、备案和信息变更等业务, 按照现行规则办理; 对于2023年5月1日后提交的登记、备案和信息变更业务, 按照《私募登记备案办法》办理; 自2023年5月1日起, 对于2023年5月1日前已提交但尚未完成办理的登记、备案和信息变更事项, 按照《私募登记备案办法》办理。具体而言, 对于2023年5月1日以后提交备案或尚未备案完成的新基金, 应当适用《私募登记备案办法》; 对于2023年5月1日前已经备案完成的基金, 按照现行规则执行, 无需整改。需要注意的是, 根据《私募登记备案办法》第五十五条规定, 若存续基金发生备案信息变更, 变更后不符合《私募登记备案办法》要求的, 基金业协会将终止办理该项变更。',\n",
       " '一、上市公司并购差异化定价金杜研究院之前的一篇文章《柳暗又花明——投资机构另谋多元化退出路径之：参与上市公司重大并购重组交易》里面列举了被上市公司并购的标的公司采取差异化定价方式的若干案例，也就是上市公司在收购标的公司股东持有的股权/份时，按每股/每元实缴出资计算，各股东拿到的定价不同。上市公司的披露报告中说，上市公司给被并购的标的公司股东一个打包价，由股东们通过自主博弈进行分配。问题是，对价分配方案真的是完全由股东们吵出来的吗？没有什么规律可循吗？通过分析上市公司对价支付细节，我们可以发现不同类别的股东，拿到了不同的对价，而这种不同体现在定价不同，也体现在对价支付手段不同。通过对交易的模拟（见下图），您有没有发现凡是种种之不同，看起来总有那么些合理。究竟是一种错觉，还是冥冥中自有定数？不是股东类别的不同导致了定价的区别，而是本来不同的股东，拿到的就是不同类别的股份/股权？我们似乎并没有在披露的标的公司的近三年的财务报表（或模拟财务报表）中看到实收资本/股本下面有不同分类。有没有可能是因为新公司法还没有生效？相关的配套规则尚需到位？二、类别股份新公司法第144条算是给了股份有限公司的类别股份设置真正的名分，不过有限公司还是不行，毕竟股权还没有按份切片的资格。为了比照，我们把合伙企业涉及合伙人权利不对等的类似安排也放进来。关于附带特殊权利的股权的会计处理和披露，证监会在《监管规则适用指引——会计类第1号》1-1（特殊股权投资的确认与分类）给出了一些参考。在谈及“关于具有重大影响但附有回售权的股权投资应当如何处理”的时候，证监会在该指引指出：“从投资方角度看，长期股权投资准则所规范的投资为权益性投资，因该准则中并没有对权益性投资进行定义，企业需要遵照实质重于形式的原则，结合相关事实和情况进行分析和判断。投资方应考虑该特殊股权投资附带的回售权以及回售权需满足的特定目标是否表明风险和报酬特征明显不同于普通股。如果投资方实质上承担的风险和报酬与普通股股东明显不同，该项投资应当整体作为金融工具核算，相关会计处理同情形1（即应分类为以公允价值计量且其变动计入当期损益的金融资产，本文作者注）。如果投资方承担的风险和报酬与普通股股东实质相同，因对被投资方具有重大影响，应分类为长期股权投资，回售权应视为一项嵌入衍生工具，并进行分拆处理。对投资方而言，持有上述附回售条款的股权投资期间所获得的股利，应按该股权投资的分类，适用具体会计准则规定进行处理。”对于被投资方，根据上述同份指引，则因为回售权的存在，无论是否投资方的投资是否具有重大影响，均应分类为金融负债处理。这也是附带对赌条件的投资常常会导致公司的净资产为负的原因，因为其在被投资方的表现完全是负债的形式。从某上市公司2022年披露的对于投资标的公司的会计处理可见端倪：目前公司投资标的公司的会计处理方式为：将已取得的标的公司股权投资作为长期股权投资按权益法核算，其中的赎回权、优先清算权等权利嵌入衍生工具作为一项金融资产分拆核算，并按公允价值进行计量，记在其他非流动金融资产科目。可惜，由于投资标的公司尚未上市，未能查到其在对应年份中对于某上市公司上述投资的会计处理。理论上，似乎应与上市公司的会计处理相互映射，即将标的公司接受的股权投资同时在资产、金融负债和实收资本中进行处理。上述实践也映衬出目前国内资产负债表的股东权益披露中，多数尚未充分考虑附带优先权利的股权投资的定位。这个情况发生的原因，可能可以部分归咎于现行公司法并不承认类别股的存在。新公司法施行之后，理论上会需要重新定义优先股（考虑到类别股的多样性，优先的权利表现也可能更为多样），在财务报表上扩张其他权益工具项下优先股所涵盖的范围，还是干脆参考美股的披露经验，从其他权益工具中把优先股摘出来，直接来个简单而直接的优先股、普通股先后填列的披露模式？至于具体的复杂的优先股的会计处理长期股权投资和/或金融资产和/或金融负债和/或衍生工具的各种组合则在财务报表附注中予以披露？接下来的问题是：持有不同类别股份/股权的股东，在股份/股权评估作价的过程中又需不需要被“区别对待”呢？三、标的公司估值从目前上市公司重大资产重组交易披露信息来看，目前资产评估报告所能解决的问题是企业价值（Enterprise Value）和股权价值（Equity Value）。对于股权价值如何再分配到不同类别的股份/股权之上，并没有已建立可以参照的实践做法。事实上，风险投资实践在国内发展多年，可以说在新公司法第144条出台前已经建立了比较复杂的股权结构，而相应的司法实践也已经积累了不少经验和案例。这样的积累是一笔可观的财富，并不是一句IPO前/股改时让优先权利“自始无效”、灰飞烟灭可以抹杀和消弭的。在股权价值的基础上多走一步，按股份/股权类别进行价值分配，既然已经被上市公司重大资产重组实践所确认，此类估值需求在新公司法即将施行的背景下所折射出来的迫切性不言而喻。四、他山之石之409A估值美国法下，美国税收法典（Internal Revenue Code（IRC））第409A节要求持有公司股份实值期权（in the money option，即期权所对应的公司股份的公平市场价值（fair market value（FMV）高于期权行权价（strike price））的持有人在期权授予日就应就FMV与期权行权价的差额确认收入并付税。这是期权的税收本质，也就是因为劳动关系而以低于FMV取得资产的人，应当将差额作为工资薪金所得，事实上，中国的个人所得税法规定也是如此。在美国税法下，采用FMV的方式对可变价值进行判断并征税是一个常见的操作，包括对对赌条款的税收处理（另文讨论）。换言之，当公司给与其员工股权期权激励时，要想不立即触发应税义务，就必须把行权价设定在公司普通股折算后的期权价值之上。对于上市公司而言，确定期权FMV的普通股价值基础可以通过市价确定，但是对于未上市公司，尤其是初创公司，其普通股的价值如何确定就是一个问题。在中国的税法下，对此也没有定论，常常有人以近期公司接受的投资价格作为基础，然而这十分不稳定缺乏合理的基础。Internal Revenue Service（IRS，美国国家税务署）规定了一系列操作指南以明确在采取若干合理步骤和方法的情况下，公司可以依赖独立评估机构对于其普通股的估值（即构成safe harbor）。这一源于规制安然（Enron）会计造假的制度改革，直接促成了美国非上市公司类别股份的估值发展，并建立了一系列可参照实践——想要评估公司普通股的价值，不就得把普通股之外的其他股份的价值也一并确认了？由此，股权估值更进一步，股权估值分配登场。中国法下，非上市公司进行股权激励时，目前在期权授予日并不会产生纳税义务，行权日是最早可能触发的时点（见下图，细节请参考金杜研究院的文章《境内非上市公司通过合伙平台实施的股权激励应如何缴税？》），员工因行权而直接持有的期权在满足备案等要求的情况下可以享受迟延纳税优惠。此外，不少公司股权激励是通过有限合伙平台通过增资实现，进一步减少了对于公司普通股进行专项估值的需求。虽然如此，美国409A估值所带来的复杂股权安排的估值分配实践，对于新公司法即将确立的类别股份制度而言仍具有较高的参考价值。对于投资人而言，明智的选择也必然是用投资协议条款的约定指导股权价值估值和分配，而不是在即将发生变现事件才起身博弈。一点展望在IPO严控、发行节奏趋缓的大背景下，通过上市公司重大资产重组并购交易完成退出必然成为一种选择。与IPO不同，并没有对于被并购的标的公司股东优先权利清理的强制性要求，因此对于创业企业的投资人而言，新公司法下类别股份制度当然就成为了加强投资人保护的合理选择。对于那些本想冲击IPO但不想继续等待的公司来说，投资人也迫切需要设法重新恢复可能因为股改已经受损的类别股份的安排。那么问题来了，是继续在有限公司上抱残守缺，还是直接上股份有限公司的类别股制度？',\n",
       " '2021 年 5 月 1 日, 德国《对外贸易条例》（Außenwirtschaftsverordnung, \"AWV\"）的第17次修正案正式生效。德国外商投资管制制度经过修订, 以反映 2020 年 7 月《对外贸易和支付法》（Außenwirtschaftsgesetz, “AWG”）的最新变化, 并进一步落实欧盟第2019/452号外商投资审查条例（“《欧盟审查条例》”）。这项修订扩大了申报要求的范围, 尤其是针对活跃在高科技领域的公司, 并将其他类型的收购纳入德国外商投资管制制度。同时, 第17次修正案将现有股东的某些附加收购和某些集团内部的重组排除在德国外商投资管制制度的范围之外。这些变化会影响截至 2021 年 5 月 1 日尚未签署的未决交易。德国外商投资管制制度德国外商投资管制制度由 《对外贸易和支付法》（AWG）和《对外贸易条例》（AWV）组成。仅在过去的 12 个月内, 相关制度就已历经 3 次修订, 以进一步扩大德国外商投资管制制度的适用范围。目前而言, 德国外商投资审查方式主要包括:特定行业（sector-specific）投资审查机制——适用于外国投资者（直接或间接）收购活跃在特别敏感行业的德国公司10%或以上的投票权的交易, 例如战争武器和军事设备的生产或开发以及加密技术行业。这种收购必须向德国联邦经济和能源部（\"BMWi\"）申报。如经审查, BMWi认为收购不会对德国的重大安全利益构成威胁, 则将批准交易。多行业（cross-sector）投资审查机制——来自非欧盟或欧洲自由贸易联盟（non-EU/EFTA）的投资者对符合特定门槛的德国公司投票权的任何其他（直接或间接）收购均受多行业投资审查机制的约束。如果该收购有可能损害德国或另一个欧盟成员国的公共秩序或安全, 或者损害涉及欧盟整体利益的项目, BMWi 可能会审查、限制甚至禁止收购。针对活跃在某些敏感商业领域的德国公司的收购必须向BMWi申报, 例如关键基础设施运营相关行业的收购（“须申报的收购”）。任何须申报的收购均须经 BMWi 的批准。一般审查——针对德国公司的其他外国投资不受申报要求的约束, 但仍受 BMWi 一般审查权力的约束, 如果有可能损害公共秩序和安全, 相关交易仍可能会受到限制或被禁止。在未经 BMWi 事先批准的情况下, 接收审查中的特定行业投资审查机制下以及跨行业投资审查机制下的交易仍处于未完成的状态, 任何旨在完成该等交易的法律文书都暂不生效, 部分交割措施也暂不可执行。任何违反此类禁令的行为都将受到刑事制裁, 包括最高五年的监禁和罚款。扩大跨行业投资审查和特定行业投资审查的范围最新一稿修正案大大扩展了特定行业投资审查机制的范围和多行业投资审查机制适用的行业类别, 大量对德国公司的外国投资将受制于申报要求和相应的批准要求。特定行业投资审查机制的范围涵盖对德国《出口清单》 （Ausfuhrliste） 第 I 部分 A 节所列的对开发、制造、改造或拥有军事装备的德国公司的收购。此前, 该清单上的22类行为中只有5类落入特定行业投资审查机制范围内。此外, 如果被收购的德国公司曾从事过清单中的行为, 且在被收购时仍然掌握或有机会获得该等行为所必要的专业知识和/或技术, 也足以触发特定行业投资审查机制。多行业投资审查机制的适用范围则在的现有11个类别的基础上, 增加了16个新的须申报收购类别。大多数技术和经济类活动都与《欧盟审查条例》中所列的高科技商业领域有关。这些关键新兴技术现在出现在《对外贸易条例》（AWV）中, 并受到申报和批准要求的约束, 其中包括人工智能、半导体、自动驾驶、机器人、光电子、增材制造和网络安全。并非《欧盟审查条例》中提到的所有领域的收购都被列为须申报的收购, 例如, 与 “个人数据 ”有关的活动并未被包含在内。但投资者仍需注意, 该类活动有可能被认定为对公共秩序和安全构成威胁而落入BMWi的一般审查范围内。',\n",
       " '从2020年3月最高检在6个基层检察院开展合规改革试点，到2022年4月合规改革在全国范围推开，最高检至各级检察院公示了多起合规不诉案件，其中，虚开增值税专用发票案占有相当的比例。虚开增值税专用发票作为涉企涉经营犯罪，天然契合合规不起诉制度适用。经对既有案例分析，结合办案经验，虚开案的合规不诉适用仍具有税额未突破250万、企业合规不诉负责人未能免刑、认罪认罚补税为适用前提等重难点，以下结合办案经验撰文分享。一、合规不起诉制度的推进历程与适用条件（一）推进历程：6个试点单位+10省市试点+全国范围推开2020年3月，最高人民检察院在上海市浦东新区、金山区，江苏省张家港市，深圳市宝安区、南山区，山东省临沂市郯城县人民检察院6个基层检院率先部署了企业刑事合规不起诉改革的试点工作。2021年4月，最高人民检察院发布《关于开展企业合规改革试点工作的方案》，启动了第二期企业刑事合规不起诉改革试点。试点地区扩大到北京、辽宁、上海、江苏、浙江、福建、山东、湖北、湖南、广东等10个省、直辖市。据统计，试点范围扩展到62个市级院、387个基层院。2022年3月8日，张军检察长在最高人民检察院工作报告时指出，“2021年，涉企等单位犯罪不起诉率38%，同比增加5.9个百分点。”，“检察机关积极稳妥推进，全年不批捕38.5万人、不起诉34.8万人，比2018年分别上升28.3%和1.5倍。”2022年4月2日，最高人民检察院会同全国工商联专门召开会议，深入总结两年来检察机关涉案企业合规改革试点工作情况，并正式“官宣”——涉案企业合规改革试点在全国检察机关全面推开。（二）适用条件：涉企犯罪+认罪认罚+实体企业+自愿适用根据最高人民检察院发布的《关于建立涉案企业合规第三方监督评估机制的指导意见（试行）》第四条，同时符合以下4个条件的刑事案件，可以适用第三方监督评估机制：1、涉企犯罪案件；2、涉案企业、个人认罪认罚；3、涉案企业能够正常生产经营，承诺建立或者完善企业合规制度，具备启动第三方机制的基本条件；4、涉案企业自愿适用第三方机制。同时，具备以下情形之一的，将被排除适用企业合规试点以及第三方机制：1、个人为进行违法犯罪活动而设立公司、企业的；2、公司、企业设立后以实施犯罪为主要活动的；3、公司、企业人员盗用单位名义实施犯罪的；4、涉嫌危害国家安全犯罪、恐怖活动犯罪的；5、其他不宜适用的情形。二、14起虚开案件适用合规不起诉汇总分析（一）14起合规不起诉虚开案件汇总在今年的两会记者会中，最高检披露，虚开发票类案件约占合规不起诉案件总数的三分之一。我们选取以下14起案件作为样本，提炼关键词以分析，其中13起为虚开增值税专用发票，1起为虚开普通发票。（二）虚开案件合规不起诉适用共性分析1、涉虚开增值税专用发票案件是最主要的虚开案件类型；2、江苏省、浙江省是目前虚开合规不起诉案件最多的地区；3、虚开合规不起诉案件的涉税数额均在250万以下（11起案件涉税数额在50万以下，3起案件数额在50万-250万区间，且其中2起案件超过200万）；4、合规不起诉主体不仅包括受票企业及其责任人，还包括开票企业及其责任人、介绍人。并且从文书披露信息可知，开票企业及其责任人、介绍人等主体取得合规不起诉结果，以受票企业补缴税款并获得合规不起诉结果为前提；5、认罪认罚、补缴税款为适用条件，多数案件还具有自首情节，2起税额超200万的案件，除认罪认罚、补缴税款之外，分别具有立功、从犯法定减轻情节，再次凸显虚开犯罪合规不起诉制度在税额上的适用上限。三、办案手记：企业涉虚开增值税专用发票罪合规不起诉完整流程根据最高检《指导意见》及其实施细则，结合办案经验，我们将虚开案件合规流程整理如下：1、启动：刑事合规不起诉制度的启动，可以由人民检察院主动审查是否符合适用条件，也可以由涉案企业申请适用，但最终适用需要企业提出申请，并签署认罪认罚具结书，检察机关层报省检院同意后启动实施。2. 成立评估小组、形成工作方案：涉虚开增值税专用发票案件中，税务机关工作人员在评估小组专家成员中，无论是意见分量还是人员占比都具有重要地位。3、提交合规计划：涉案企业提交专项或者多项合规计划，主要围绕虚开增值税专用发票案件，反映出的企业存在的，财务管理不规范、业务审批流程不规范、税务合规意识欠缺等方面问题，制定可行的合规管理规范，并明确合规计划的承诺完成时限，需要关注的是，涉虚开案件，企业暴露出来的风险更多集中在财务、税务管理方面，故合规计划制定应体现在制定规范的《财务管理制度》《资金收付审批制度》《发票管理规范》等方面，突出重点。4、审查合规计划：评估小组对企业合规计划的可行性、有效性与全面性进行审查，提出修改完善的意见建议，并根据案件具体情况和涉案企业承诺履行的期限，确定合规考察期限。5、执行合规计划：涉案企业按照合规计划的事项和期限，执行合规计划。包括制定制度文本、员工学习情况视频资料、聘请外部财税专家就发票管理规范培训情况等。6、检查、评估、考核：在合规考察期内，第三方组织可以定期或者不定期对涉案企业合规计划履行情况进行检查和评估；在合规考察期届满后，第三方组织对企业的合规计划完成情况进行全面检查、评估和考核。合规情况的考察/抽查包括实地检查、分别单独询问业务财务等部门成员、查看企业账簿资料等方式。企业应格外关注，不能只是纸面上的合规。7、评估小组出具《评估报告》：第三方组织制作合规考察书面报告，报送检院。8、召开听证会：检院组织评估小组专家、企业代表、办案人员等召开听证会，听证会上，评估小组专家成员到会发表意见。9、作出不起诉决定：合规整改通过，企业补缴税款、滞纳金、罚款等，检院召开检委会，作出《不起诉决定书》。10、刑行反向衔接：结合涉案企业合规计划完成情况及第三方组织参与的听证会情况，仍有涉及到需要税务处理处罚的，转税务机关。四、虚开刑案适用合规不起诉适用的四个难题（一）界限：税额250万元以上案件，暂无适用合规不起诉在已公布的合规不起诉虚开案件中，涉案税额超过200万元的有2起。目前尚无税额250万元以上适用合规不起诉的案件。根本原因在于，合规不起诉所依赖的基础制度是刑事诉讼法中的酌定不起诉——“对于犯罪情节轻微，依照刑法规定不需要判处刑罚或者免除刑罚的，人民检察院可以作出不起诉决定”。因此，合规不起诉的适用，从内在要求上，必须符合“犯罪情节轻微”的条件。前述2起税额200余万的案件，成功适用合规不起诉得益于具有从犯、立功等法定从宽情节，在量刑幅度上获得了减档到3年以下的机会。但是税额250万元以上的案件，法定刑为十年以上，即使存在减档情节，也难以降到3年以下，因此，适用合规不起诉存在制度障碍。此时，需要律师更加细致把握案件证据链条的基础上，梳理交易类型降低指控金额、分析案涉交易事实寻求变更罪名（非法购买、虚开发票等）等方向，寻找合规不起诉制度的适用空间。（二）两难：合规不起诉与无罪辩护两条路径恐不能兼得根据《指导意见》第四条，涉案企业、个人认罪认罚是合规第三方机制适用的必要条件之一。由此，根据当前制度设定，适用合规不起诉与无罪辩护成为两条对立的处理路径。在构成犯罪没有争议的情况下，合规不起诉无疑为争取从宽处罚提供了有效途径。但在是否构成犯罪尚不清晰的情况下，合规不起诉的适用则会严重限缩无罪辩护的空间。面对无罪辩护的低成功率与高时间成本，涉案企业及人员为了能够更有把握地获取从宽处理结果，争取企业生存发展的机会，往往会选择放弃自我辩护权利，来寻求合规不起诉适用。而此种情形下，审查起诉阶段检察机关可能会放松对案件本身是否构罪的审查。这就导致本不属于犯罪的案件可能会被认定构成犯罪，错误认定某种交易模式的性质，给行业和地区的经营活动带来不利影响。并且，企业申请合规不起诉并不一定会通过检察机关的审查，一旦合规不起诉的路径丧失，进行无罪辩护无疑会变得更加困难。根据我们的办案经验，在签署认罪认罚具结书后，检察院会以此为据坚定对犯罪的指控，法官也可能因此对案件构成犯罪加强内心确认。合规不起诉的适用失败使得案件面临更大的风险。提醒涉案企业、人员面对这一两难选择时，要更加慎重。合规不起诉与无罪辩护矛盾的调和需从制度设置入手。虽然认罪认罚作为合规不起诉的适用条件具有其合理性，但就虚开案件来讲，仍应考虑虚开增值税专用发票罪与非罪认定，理论及司法实践仍存较大争议的现实，给与企业无罪辩护空间。（三）风险：企业适用合规不起诉，个人却被起诉判刑合规不起诉制度适用于涉企犯罪案件，即单位犯罪案件，各项适用条件也均是针对涉案企业设定。由此，部分地方的检察人员认为，第三方机制适用后，企业可以免于起诉，但是相关负责人仍然需要承担一定刑事责任，只能减轻处罚而无法免于起诉。2021年10月11日最高检发布的《人民检察院行刑衔接工作典型案例》中的上海R公司、T公司、姜某虚开增值税专用发票案就是这样一起案件。这提醒涉案企业和个人要关注合规不起诉企业和个人可能差别对待的风险。根据刑法理论和规定，涉税单位犯罪要按照“双罚制”处罚单位和个人。但是，个人实际上只是单位犯罪承担责任的主体，并不是犯罪主体，因此，个人承担的刑事处罚其实来源于单位承担的刑事处罚。由此，如果单位免受刑事处罚，个人也不应再承担的刑事处罚。单位能够适用合规不起诉制度，个人也应随之适用，否则明显违背刑法原理，也将削弱合规第三方机制的适用效果。在前述14起案例中，不仅受票企业获得了合规不起诉结果，受票企业的责任人，甚至开票企业及其责任人以及介绍人都随之不起诉。这些案例的处理结果值得肯定。（四）提醒：合规不诉不是终点，处理好行刑程序衔接根据《指导意见》第十四条的规定，人民检察院对涉案企业作出不起诉决定，认为需要给予行政处罚、处分或者没收其违法所得的，应当结合合规材料，依法向有关主管机关提出检察意见。人民检察院通过第三方机制，发现涉案企业或其人员存在其他违法违规情形的，应当依法将案件线索移送有关主管机关、公安机关或者纪检监察机关处理。因此，取得合规不起诉结果并不意味着涉案企业可以高枕无忧。合规不起诉只意味着刑事程序已经处理完毕，企业避免了刑事处罚，但是，如果企业构成行政违法的，还需要承担行政责任。因此，在程序回转后，企业仍需要采取充分的措施积极应对行政程序，从定性是否正确、处罚依据是否充足、处罚轻重是否适当，处理处罚的程序是否正当等角度进行抗辩。另外，如果企业最终被予以行政处罚，企业要设法解决生存困难。企业进入刑事程序，往往负责人会被采取强制措施，企业生产停滞，因此在获得合规不起诉结果之后，企业通常需要一定的时间恢复经营。此时如果面临的罚款金额较大，企业可能一时间难以承受。对此，企业应争取税务机关的从宽处罚，还可以按照《税务稽查案件办理程序规定》的规定，向税局申请暂缓或分期缴纳罚款，以渡过暂时的生存困境。',\n",
       " '引言：国际标准化组织于昨天（2021年4月13日）正式发布ISO 37301：2021《合规管理体系要求及使用指南》（Compliance management systems — Requirements with guidance for use）。ISO 37301标准由国际标准化组织下属的ISO/TC309组织技术委员会制定，修订并代替了国际标准化组织于2014年发布的《合规管理体系—指南》（ISO 19600：2014）。编者按：我国国家标准化委员会于2017年等效采用国际标准ISO 19600：2014《合规管理体系—指南》，发布了GB/T35770-2017《合规管理体系指南失效/废止》。该指南于2018年7月1日生效。ISO 37301：2021《合规管理体系要求及使用指南》适用于全球任何类型、规模、性质和行业的组织，旨在为建立、运行、评估、维护和改进组织的合规管理体系提出要求和指南。我国企业建立合规管理体系，应当：1. 了解组织环境以及相关方的需求和期望，确定建立合规管理体系的范围，识别合规义务，开展合规风险评估。2. 治理机构和领导层应当领导并承诺建立合规管理体系，明确各层级组织（治理机构、管理层、合规组织、员工）的合规职责，建立合规管理组织，制定合规政策，建设、维护和推动组织各层级的合规文化建设。3. 制定合规目标，规划应对合规风险与机会的措施，并有计划地对合规管理体系进行改进。4. 对合规管理体系建设、运行维护和持续改进提供支持，包括资源分配、人员安排、人员招聘、合规培训、合规意识培养、沟通与交流、文件管理等。5. 做好与合规管理相关业务流程的规划、实施和控制，对合规义务和相关合规风险进行管控，鼓励违规举报，开展独立违规调查。6. 对合规管理体系的运行进行监测，明确合规绩效评价的信息来源，制定合规绩效评价指标，提交合规报告，做好合规记录。7. 对合规管理体系的有效性定期进行内部审计，以及治理机构和领导定期对合规管理体系进行评估。要求持续改进合规管理体系的适当性、充分性和有效性。当出现不合规时，及时应对整改。与ISO 19600：2014《合规管理体系—指南》相比，ISO 37301：2021《合规管理体系要求及使用指南》为要求类（即A类）管理体系标准，企业可以用于自我内部审核、对商业伙伴进行审核以及第三方审核认证（即ISO体系认证）。对于ISO体系认证，从较早的ISO 9000质量体系认证（贯标）到现在的QHSE（质量、健康、卫生、环境）体系认证，我国企业对其重要性和必要性都有着深刻的体会和认识。ISO 37301合规管理体系认证，其重要性同样不言而喻，能够帮助企业提高企业诚信，树立良好形象；促进整体管理能力提升，提高市场（尤其是国际市场）核心竞争力；创造“刑事合规不起诉”的基本条件；为合规管理体系项目的验收、评价、审计提供指导；为商业伙伴的合规管理提供可以信赖的依据，等等。尤其是，如同ISO 9000质量体系认证一样，ISO 37301合规管理体系认证势必成为企业成为其它组织商业伙伴的基本资格要求，这对我国企业贯彻落实“一带一路”战略、参与国际市场竞争至关重要。对此，我国企业必须有清晰的认识，早做准备，未雨绸缪。尽早建立并有效运行合规管理体系，一旦条件成熟，尽早获得ISO 37301合规管理体系认证。我国企业应积极应对我国中央企业大多已经按照国务院国资委《中央企业合规管理指引（试行）》建立合规管理体系，并正在推动各子公司建立和有效运行合规管理体系。不少省、自治区和直辖市也颁布实施了本省、自治区、直辖市所属国有企业的合规管理指引，并着手推动本省、自治区、直辖市所属国有企业的合规管理体系建设工作。需要注意的是：1. 建议在贯彻执行国务院国资委《中央企业合规管理指引（试行）》和有关省、自治区、直辖市所属国有企业合规管理指引的基础上，对标ISO 37301：2021《合规管理体系要求及使用指南》，查缺补漏，完善本企业合规管理体系；2. 关注合规管理体系的有效落地运行，落实合规管理体系的绩效评价、审计和持续改进，避免止步于合规管理体系框架搭建，避免形式主义；3. 大力培养合规管理人才；4. 部分省、自治区、直辖市尚未制定本省、自治区、直辖市所属企业的合规管理指引，也尚未启动所属企业的合规管理体系建设工作，建议立即行动起来。2019年12月22日，中共中央和国务院联合发布了《中共中央国务院关于营造更好发展环境支持民营企业改革发展的意见》（以下简称“意见”）。要求我国民营企业要筑牢守法合规经营底线，依法经营、依法治企、依法维权，认真履行环境保护、安全生产、职工权益保障等责任。2021年3月11日，十三届全国人大四次会议表决通过了关于国民经济和社会发展第十四个五年规划和2035年远景目标纲要的决议，要求我国社会主义各类市场经济体加强合规管理，依法合规经营，尤其突出了企业境外风险管控和民营企业合规经营的重要性。但是，我国大多数民营企业的合规管理尚未起步，重大违规事件频发，情况堪忧。ISO 37301：2021《合规管理体系要求及使用指南》已然发布，我国民营企业必须尽早觉醒：建立合规管理体系将是你们成为合格的商业伙伴、参与国际市场竞争的基本资格条件！我国民营企业开展合规管理、建立合规管理体系，刻不容缓！我国发改委等七部委于2018年12月26日发布实施了《企业境外经营合规管理指引》。十三届全国人大四次会议表决通过的关于国民经济和社会发展第十四个五年规划和2035年远景目标纲要的决议，突出要求加强企业境外风险管控与合规管理。我国企业境外投资经营，直面所在外国市场竞争和国际市场竞争，需要基于经营所在外国属地法律、法规，按照我国发改委等七部委《企业境外经营合规管理指引》以及ISO 37301：2021《合规管理体系要求及使用指南》建立和有效运行合规管理体系。我国境内相关企业集团，作为境外投资经营的主体和母公司，需要适当突破在人员、预算等方面的国内管理模式，对标跨国企业集团，在加强集团管控的同时，在法务、合规、内控、风控等方面加大对境外企业的投入和支持。',\n",
       " '司法观点用人单位未能说明倒签劳动合同的合理性，亦未能举证证明实际用工后已及时通知劳动者签订劳动合同、与劳动者就订立合同一事进行磋商的，应认定倒签行为无效，用人单位无权据此主张免除未订立书面劳动合同的责任。知识点：1、倒签劳动合同日期的行为合法性的不同司法观点2、倒签劳动合同无效的例外情形3、劳动者不同意订立劳动合同时，用人单位如何应对？4、补签、倒签和代签劳动合同的区别有哪些？……详情见下文????经典案例2012年4月1日，吕某进入A公司工作。由于此时A公司尚在筹建期间，故由B公司为吕某代扣代缴了2012年4月至2012年11月期间的个人所得税。2012年11月16日，A公司成立。2013年5月9日，A公司与吕某签订了期限为2012年4月1日起的无固定期限劳动合同书一份，合同的落款日期为2012年4月1日。2013年5月20日，吕某主动离职。2013年5月21日，吕某向劳动人事争议仲裁委员会申请仲裁，要求A公司支付2012年12月16日至2013年5月8日期间未签订劳动合同的双倍工资差额。仲裁委裁决支持了吕某的仲裁请求。A公司不服该裁决，依法起诉。庭审中，A公司称其于2012年4月1日就与吕某签订了无固定期限劳动合同，故无需支付二倍工资。法院认为首先，鉴于在系争的工作期间内吕某并未与A公司按常理签订书面劳动合同，故本院应当根据提供劳动的实际情况，从劳动者对用人单位的从属性出发，依据劳动者是否接受用人单位的管理来认定本案劳动关系建立与否及建立时间。本院认为吕某自2012年11月16日起方与A公司建立事实劳动关系，原因如下：第一，2012年4月1日至同年11月16日，A公司尚在筹建期间，尚不具备用工的主体资格，而在2012年11月16日公司成立之后，A公司无证据证明其已经或者曾要求与吕某就之前的劳动关系进行追认，此外，A公司也未提供明确证据证明其已告知吕某系与其建立劳动关系。第二， 2012年11月16日A公司成立后，吕某的所得税缴纳、薪酬支付、调休单发放等转由A公司管理。故本院认为吕某自2012年11月16日起与A公司建立事实劳动关系。其次，根据劳动合同法的相关规定，用人单位应当自用工之日起一个月内与劳动者订立书面劳动合同，否则应当依法向劳动者支付未订立书面劳动合同的双倍工资差额。本案中，A公司与吕某2013年5月9日签订的书面劳动合同中虽约定合同生效日期为2012年4月1日，但该合同明显为倒签，证明实际用工开始之后，A公司并未依法与吕某订立书面劳动合同，故不能免除A公司需承担的未订立书面劳动合同的民事责任。据此，A公司关于已自2012年4月1日起与吕某订立无固定期限劳动合同，故无需支付双倍工资差额的主张，缺乏事实与法律依据，本院不予认可。故，法院判决A公司向吕某支付2012年12月16日至2013年5月8日期间未签订劳动合同的双倍工资差额。律师点评上述典型案例涉及到了对倒签劳动合同日期合法性的认定，我们对此作几点阐释：1、倒签劳动合同日期的行为合法性的不同司法观点倒签劳动合同日期是指用人单位招录用工后，没有在法定期限内签订劳动合同，待一段时间后签订劳动合同时再将合同日期签订为建立劳动关系之日。这种倒签行为会导致实际签订之日与合同载明签订之日不一致的情况。有很多用人单位会为避免承担未在法定期限内签订劳动合同的法律责任，而倒签劳动合同。因此，为保护劳动者的合法权益不被侵害，法院在审查倒签行为合法性时会更为严格。司法实践中，对于倒签行为的合法性存在两种截然不同的观点：第一种观点认为，倒签行为违反了用人单位应自用工之日起一个月内订立书面劳动合同的规定，故倒签行为不合法，不能据此免除用人单位支付二倍工资的责任。上海地区很多法官持这种观点；第二种观点认为，如果倒签行为不存在胁迫劳动者的情形，则应认定劳动者对倒签后的合同进行了认可。劳动者同意倒签劳动合同表明其已放弃了用人单位支付未签订劳动合同期间二倍工资的权利。广东地区大部分法院都持这种观点。最高人民法院认为，倒签劳动合同与《劳动合同法》的立法本意相悖，不利于保护劳动者权益，是用人单位为规避二倍工资的借口，倒签劳动合同应付二倍工资。2、倒签劳动合同无效的例外情形原则上，倒签劳动合同行为应认定为无效，如有以下情形，应认定倒签行为是合法有效的：用人单位并非故意不订立劳动合同。用人单位在用工之后及时向劳动者发送了要求订立劳动合同的通知，同时也多次与劳动者进行磋商，但因劳动者个人原因，导致双方迟迟未订立原因。最终，双方协商一致同意签订劳动合同，并同意将签订日期倒签。在这种情况下，未订立书面劳动合同不可归责于用人单位，故不宜认定倒签行为是无效，从而让用人单位承担二倍工资的法律责任。在用人单位已采取合理措施要求订立劳动合同的前提下，法院会认定未订立书面劳动合同系劳动者自身原因，用人单位无需承担二倍工资的责任。公司治理建议1、劳动者不同意订立劳动合同时，用人单位如何应对？实践中，很多劳动者会因为各种原因不同意订立劳动合同。用人单位遇到这样的劳动者，切忌消极应对。如果用人单位不采取任何措施，即使不订立书面劳动合同是劳动者本人的真实意思，法院也会认定用人单位须承担二倍工资的责任。用人单位首先应与劳动者积极沟通，并向劳动者发送要求与劳动者订立书面劳动合同的通知，如果一个月内劳动者仍不同意订立劳动合同，建议用人单位与其终止劳动关系，以免增加不必要的用工风险。如果系劳动者身份特殊，即便公司未与其签订劳动合同也不承担未签劳动合同的双倍工资。2、补签、倒签和代签劳动合同的区别补签与倒签合同都是将合同期限往前移，将前段未签合同的期限予以覆盖。但两者的不同点在于，补签的落款日期是签订的当前日期，但倒签的落款日期是劳动关系建立之初的时间。例如用人单位与劳动者实际在2017年8月1日签订期限从2016年4月1日起的劳动合同，如果合同落款载明的签订日期为2017年8月1日，则为补签；如果载明的签订日期为2016年4月1日，则为倒签。对于代签行为，用人单位应尽量让劳动者当面签，以避免劳动者找他人代签。即使受客观条件所限，必须要找人代签，用人单位也应要求劳动者本人出具代签劳动合同的授权委托书、情况说明书，同时要注意保留劳动者本人同意他人代签的证据。如果用人单位有证据证明代签劳动合同经劳动者本人同意，或劳动者以实际行为表明接受所代签劳动合同内容，且劳动合同并不违反法律、法规强制性规定，代签的劳动合同合法有效。代签、补签、倒签劳动合同都有可能产生未订立劳动合同二倍工资的风险。（本文来源于 公众号 公司法研）',\n",
       " '私募基金管理人登记是投资机构募集私募基金的必要条件，而私募基金备案则是私募基金可以正式开始投资运作的前提。因此，私募基金管理人登记和私募基金备案一直以来都是各投资机构在开展业务过程中极为重视的环节，也会为此尽力达成各项合规要求，以免业务开展被“卡脖子”。2022年6月2日，中国证券投资基金业协会（以下简称“基金业协会”）发布了《关于私募基金管理人登记备案工作相关事宜的通知部分失效/废止》，对其此前发布的《私募基金管理人登记申请材料清单》加以更新，同时系统整合了私募基金备案的关注要点，本所已撰文深度解读。实际上，私募基金管理人登记和私募基金备案远非私募合规的终点，私募基金管理人登记和私募基金备案的相关规定也不仅是对管理人登记、基金备案时点的要求，持续性合规运营要求贯穿于私募基金管理机构和私募基金的整个运作过程之中。本文拟整体梳理私募基金管理人完成登记及私募基金完成备案后，私募基金管理人需要持续关注和履行的合规义务，为各私募基金管理人的合规运营指路。根据面对对象的不同，可以将各类合规事项按对投资者和对监管机构须履行的不同义务分别加以说明。一、对投资者由于私募基金管理人与投资者之间信息的不对称性，二者之间的信息沟通机制就成了私募基金管理人合规工作的重中之重。私募基金管理人与投资者之间的信息不对称是双向的，一方面，私募基金管理人难以了解投资者对投资的偏好和承担投资风险的能力；另一方面，投资者难以了解受托管理其资金的私募基金管理人如何实际开展投资业务。因此，私募基金管理人对投资者的合规义务主要体现在适当性管理和信息披露两个方面，而这两个方面也是贯穿私募基金募集到运营的全过程的。（一）投资者适当性管理投资者适当性是指基金募集机构在销售基金产品或者服务的过程中，根据投资者的风险承受能力销售不同风险等级的基金产品或者服务，把合适的基金产品或者服务卖给合适的投资者。——《基金募集机构投资者适当性管理实施指引（试行）》第三条01投前适当性审核根据《私募投资基金募集行为管理办法》的规定，私募基金的募集应当履行一定的必要流程，包括特定对象确定、投资者适当性匹配、基金风险揭示、合格投资者确认、投资冷静期和回访，其中就已明确了投资者适当性匹配的要求。后续《证券期货投资者适当性管理办法已被修订》《证券经营机构投资者适当性管理实施指引（试行）》及《基金募集机构投资者适当性管理实施指引（试行）》的相继出台则进一步细化了投资者适当性管理的具体要求，不仅将投资者区分为普通投资者和专业投资者进行差异化管理，还对基金募集完成后的持续性投资者适当性管理提出了要求。02投后适当性自查和回访根据前述规定，私募基金管理人应当每半年开展一次适当性自查，形成自查报告，且应建立健全普通投资者回访制度，对普通投资者定期抽取一定比例进行回访，对持有R5等级基金产品或者服务的普通投资者增加回访比例和频次。参考基金业协会发布的《基金产品或者服务风险等级划分参考标准》，私募股权、创业投资基金通常会被划分R5等级的基金产品，因此如果私募基金管理人所管理的私募基金的投资者中有普通投资者，则应注意履行定期回访义务。结合适当性自查的频次要求，可考虑在适当性自查的同时一并安排普通投资者回访。03CRS年度回访需要提示的是，除了适当性管理义务外，根据2017年7月1日实施的《非居民金融账户涉税信息尽职调查管理办法》的要求，私募基金管理人还应当建立实施监控机制，按年度评估非居民金融账户涉税信息尽职调查和信息报送制度、业务流程并检查相关执行情况。因此，私募基金管理人还可以在适当性自查时向投资者核实最新的非居民金融账户涉税信息。小结：私募基金管理人在推介私募基金前和完成私募基金募集后都应严格落实投资者适当性管理，每半年开展一次投资者适当性自查；每年开展一次投资者非居民金融账户涉税信息复核；并建议同时进行普通投资者回访，回访频率建议不低于每年一次。该等工作均应留下书面记录存档。（二） 信息披露01基金募集阶段的信息披露如前所述，风险揭示是私募基金募集推介的必要环节之一，而风险揭示的内容正是私募基金管理人在私募基金募集阶段就应向投资者披露的信息之一。除了风险揭示外，《私募投资基金募集行为管理办法》和《私募投资基金信息披露管理办法》均对私募基金募集推介材料应披露的内容作出了具体规定，募集推介材料也是私募基金备案时需要上传基金业协会审核的材料之一。02基金运作期间的信息披露在完成私募基金备案、私募基金开始投资运作后，私募基金管理人更应按照相关监管规定及基金合同的约定，定期向投资者履行信息披露义务。以私募股权、创业投资基金为例，根据《私募投资基金信息披露内容与格式指引2号》的要求，私募基金管理人至少应定期向投资者披露半年度报告和年度报告，其中半年度报告应在当年9月底之前完成，年度报告应在次年6月底之前完成。同时，基金业协会鼓励私募基金管理人向投资者披露季度报告，但不做强制要求。实践中，大部分主流的私募基金管理人会结合投资者的要求，在基金合同中约定更严格的信息披露要求，比如定期披露季度报告、半年度报告和年度报告，或在基金业协会要求的基础上提高信息披露的效率。此外，《私募投资基金信息披露管理办法》还就若干重大事项规定了私募基金管理人根据基金合同约定的披露义务。实践中，基金合同未必就其中提到的每一重大事项都具体约定了披露要求，但通常我们仍建议私募基金管理人能在发生该等情形时及时向投资者披露，既是对投资者权益的保护，也是在极端情形下发生相关争议时对私募基金管理人自身的保护。实际上，基金业协会也通过信息报送手段对前述重大事项的披露加以监督和控制，因为该等重大事项大多涉及基金合同的变更（基金合同发生变更的，私募基金管理人应进行产品重大事项变更），或是会在私募基金管理人的控股股东、实际控制人或法定代表人/执行事务合伙人委派代表发生变更时要求提供私募基金管理人向投资者的通知及回复证明材料。03信披系统投资者查询账号的开立实践中，私募基金管理人通常会通过电子邮件的形式向投资者进行信息披露。《私募投资基金信息披露管理办法》提到的基金业协会指定私募基金信息披露备份平台，即私募基金信息披露备份系统（以下简称“信披系统”）于2020年2月14日正式上线定向披露功能模块后，私募基金管理人还应在私募基金完成备案后，及时为投资者开通信披系统查询账号，让投资者得以通过信披系统获取信息披露报告。自2021年第二季度起，基金业协会陆续在私募基金管理人信息公示平台、私募基金信息公示平台公开私募基金管理人及单支私募基金的投资者查询账号开立率，若私募基金管理人为投资者开立账户的比率低于50%（不含50%）的，私募基金管理人公示平台“机构提示信息处”还将出现特别提示。虽然该等提示暂时不影响私募基金管理人备案新基金，但信披系统投资者查询账号的开立情况将纳入基金业协会私募基金管理人会员信用信息报告指标体系，并与私募基金备案分道制安排相关联，这将可能影响私募基金管理人信用评价及备案新基金的效率，希望私募基金管理人能加强关注。小结：私募基金管理人在推介私募基金环节和完成私募基金募集后都应严格遵循相关监管规定和基金合同的约定进行信息披露，包括但不限于半年度报告、年度报告、重大事项报告，且应在完成私募基金备案后及时开立信披系统投资者查询账号。二、对监管机构我国私募基金行业的监管部门为证监会，而基金业协会是根据《证券投资基金法》成立、并根据《私募投资基金监督管理暂行办法》等规定运作的基金行业自律组织，对私募基金业开展行业自律，协调行业关系，提供行业服务，促进行业发展。目前，除了作为上位法的《证券投资基金法》外，针对私募基金行业的各项规定主要来自证监会的部门规章和基金业协会的行业自律规则。其他相关部门也会对其管理条线内涉及私募基金的一些方面加以规制。仅为本文之目的，暂且将前述对私募基金行业有规范要求的部门统称为私募基金的监管机构。私募基金行业作为强监管的金融行业的细分领域之一，监管机构对私募基金运作信息的需求是不言而喻的。同样由于信息不对称性，监管机构针对私募基金管理人制定了一系列信息报送规则。对私募基金管理人而言，除了特殊情况下监管机构临时的特殊要求，其对监管机构需要履行的常规义务主要是信息报送义务。（一）证监局01初始报到根据属地管辖原则，地方证监局是私募基金管理人的直接监管部门。《私募基金管理人登记须知失效/废止》规定，新登记完成的私募基金管理人应自登记完成后的10个工作日内主动与注册地所属地方证监局取得联系，且基金业协会在给新登记完成的私募基金管理人的通知邮件中也会再次提示。02合规自查或抽查近年来，监管部门越来越重视私募基金行业的合规运作。每年，各地证监局都会对辖区内全部或部分私募基金管理人下发合规自查通知，限期要求辖区内的私募基金管理人按通知要求提供自查报告、材料底稿或其他补充说明文件，部分地区的证监局还会抽取一定比例的私募基金管理人进行现场核查，并对其中不合规者开出罚单。自查、抽查的内容和严格程度各地或有不同，但整体呈趋严态势。建议私募基金管理人在对证监局合规自查或抽查加强重视、严谨报送的同时，日常也应完善档案管理工作。小结：私募基金管理人在完成登记后，应在10个工作日内主动联系地方证监局，且应根据地方证监局的自查或抽查要求及时报送各项要求的材料。（二）基金业协会私募基金管理人对基金业协会的信息报送义务主要通过三个线上平台实现，分别是资产管理业务综合报送平台（以下简称“Ambers系统”）、信披系统和从业人员管理平台。01Ambers系统Ambers系统是私募基金管理人最常用也最熟悉的平台，从申请私募基金管理人登记到申请私募基金备案，都是通过Ambers系统完成的。而在完成私募基金管理人登记和私募基金备案后，私募基金管理人仍然需要频繁光顾Ambers系统。就私募基金管理人的信息报送而言，Ambers系统中最常用的功能是管理人重大事项变更和管理人信息更新，前者需要基金业协会审核，而后者则免于审核。近年来，管理人重大事项变更的范围经历了多次简化，目前仅包括主体资格证明文件及相关内容变更、出资人变更、实际控制人/第一大股东变更和高管变更。其他内容如发生变化，均可通过管理人信息更新功能实现，大大提高了私募基金管理人信息报送工作的效率和便捷度。《私募投资基金管理人登记和基金备案办法（试行）失效/废止》规定，私募基金管理人发生重大事项的报送时限为10个工作日，在实操中我们注意到，对于超出报送时限较长时间的私募基金管理人，基金业协会可能会反馈要求特别说明未及时报送的原因，但并不必然导致该等变更难以通过。就管理人信息更新，Ambers系统中要求私募基金管理人每年至少应当维护一次信息。此外，Ambers系统还有财税相关信息报送板块，包括年度经审计的财务报告更新和CRS年度报告，报送时限通常是每年的6月30日前。其中CRS年度报告板块是2021年上线的，将私募基金管理人每年向国家税务部门报送非居民金融账户涉税信息的义务合并到统一平台实现，方便了私募基金管理人履行信息报送义务。但需要提示的是，CRS年度报告板块简化的只是非居民金融账户涉税信息报送，在此之前，私募基金管理人在做税务信息申报时，仍然需要先在国家税务总局多边税务数据服务平台进行CRS数据申报，即进行零申报或者非零申报。就私募基金的信息报送而言，Ambers系统中最常用的功能是产品重大变更和产品季度更新。同样，前者需要基金业协会审核。产品信息更新的内容主要包括更新投资人信息和对应的风险揭示书，以及投资项目的基本信息。除此之外，如果私募基金的其他备案信息发生变化，均应提交产品重大变更。《私募投资基金管理人登记和基金备案办法（试行）失效/废止》规定，产品重大事项变更应在5个工作日内办理。对于逾期办理变更的情形，目前在我们的实操中暂未碰到基金业协会采取具体处罚措施的情况，但理论上可能存在被责令整改、对主要责任人员采取警告措施，情节严重的向证监会报告，建议仍应在能办理的情况下尽快办理。产品季度更新的时限通常为每季度结束后一个月内。此外，私募基金管理人也应在每年6月30日前通过Ambers系统提交私募基金的年度财务监测报告。02信披系统如前文所述，投资者可以通过信披系统获取信息披露报告，这也正对应着私募基金管理人在信披系统的报送义务，即在完成给投资者的信息披露报告后，在信披系统进行备份，包括但不限于半年度报告、年度报告和重大事项临时报告。03从业人员管理平台从业人员管理平台有机构管理员登陆端口和个人登录端口。私募基金管理人应该指定机构管理员及时在从业人员管理平台更新入职与离职人员的信息，为具备从业资格取得条件的员工申请基金从业资格，还可以通过从业人员管理平台统一管理机构从业人员每年的后续培训情况。需要提示的是，私募基金管理人信息公示平台显示的全职员工人数和取得基金从业人数均是从从业人员管理平台抓取的数据。如果未能及时更新从业人员管理平台，则私募基金管理人公示平台也会显示错误的信息。同时，这也意味着从业人员管理平台内需要录入的并非只有具有基金从业资格的人员，而是全体员工均应录入，这是我们实操中碰到不少私募基金管理人存在的误区。小结私募基金管理人在完成登记后，应定期登录Ambers系统更新私募基金管理人和私募基金的信息，在规定时间内进行重大事项变更；及时登录信披系统完成信息披露报告的备份；及时更新机构人员信息并进行从业资格管理。本文梳理了私募基金管理人在日常运营过程中需要向投资者和监管机构分别履行的主要合规义务，希望能在加强私募基金管理人对投资者适当性管理、信息披露和信息报送工作的重视的同时，对私募基金管理人的合规实操有所助益。',\n",
       " '我们通常会要求品牌方在与商场签订《租赁合同》时，约定“店铺销售业绩不达标的约定解除情形”的条款。例如，“自该商铺实际交付之日起2个月届满后，承租人连续6个月平均每月零售销售额未能达到**万元的，承租人提前1个月书面通知出租人后，有权无责任单方面解除合同。”该条款亦叫“逃生条款”，旨为品牌方在商场经营未达到预期收益时，能及时止损。逃生条款通常被头部品牌缔约所用，但强势的商场大抵会拒绝接受该条款；相反，部分头部商场甚至对租户有保底业绩要求。然而，二三线城市的新生商场为了吸引头部品牌入驻，通常会接受逃生条款。但这些条款往往存在隐形风险——例如，草拟的条款缺乏具体的约定和责任，只有逃生要件、没有善后约定，部分条款甚至缺乏可履行性，最终沦为“逃生条款无法逃生”。那么拟定逃生条款时该如何下手？本篇文章将从条款的有效性分析和拟定建议两方面进行展开。有效性分析首先，笔者认为“逃生条款”在不违反强制性、禁止性法律法规的情况下有效。逃生条款往往经过缔约双方的多轮商谈订立，符合双方真实的意思表示；其内容重点针对销售业绩，不违反强制性规定，更不涉及公序良俗事项。在司法实践中，绝大部分法院也认可该条款的效力。在（2020）沪0115民初10410号房屋租赁合同纠纷中，法院认为《租赁合同》约定的业绩不达标可解除合同的约定[1]有效。此外，在（2021）最高法民申1718号案件中，最高院同样确认了逃生条款属于“约定解除”的解除情形。但需要注意的是，仍有法院根据公平原则进行了补偿性调整、对条款适用的结果进行了“酌情调整”。（2021）最高法民申1718号案中，原审院和最高院肯定了“逃生条款”系有效的“约定解除”条款，但亦支持守约方向违约方支付补偿款——“守约方仍应依法合理行使约定解除权。本案系房屋租赁合同纠纷，案涉合同约定租赁期限为20年，双方已就建立长期合作关系达成了合意。原审判决出于对双方当事人利益平衡的考量，对守约方行使约定解除权加以审查，合情合理。据此，原审基于改造工程的项目范围，综合考虑A公司尚可继续利用大部分改造后的房屋、B公司实际（逃生方）使用案涉房屋的时间、合同约定的租金标准和租赁期限，按照公平原则，酌情判处B公司（逃生方）向A公司支付1815.8万元的补偿款，并无不当。”该酌情调整通过考量双方为履行合同义务付出的成本，要求逃生品牌对商场进行合理补偿，但该调整是否有悖于“意思自治原则”有待商榷。在无证据证明合同条款无效的情况下，笔者认为法院不应过度介入商事主体的交易活动，法律未对公平与否的衡量要件进行详细规制，而权利义务是否平衡往往难以在事后由第三方进行客观评价。交易合同仅为各方主体利弊权衡后的冰山一角，很难简单据此评价公平与否。而公平原则的适用应当是合同评价与调整的最后防线，在有明确约定与法律规定的情况下不应再机械、主观地进行“酌情调整”。笔者主张裁判者将“逃生条款”所蕴含的权利义务是否平衡交由交易主体和市场进行自主调节，不作过多干涉。法律或裁判者更应当慎重发挥自由裁量权，一旦法院一味以公平原则突破合同约定、对双方责任承担进行裁量，各商业主体对其订立的合同条款的信赖程度将下降、随之其商业决策效率与预期将受负面影响。在前述观点与立场之下，笔者结合实务处理经验、在下文就“逃生条款”如何拟定提出建议。细化“逃生条款”笔者在法律服务和检索过程中发现，逃生条款作为影响合同履行的实质性条款却被草拟得尤为简单，合同草拟者通常以“如果……就……”的措辞将实质性条款一笔带过。笔者建议从“逃生条款”的订立背景、限制情况、概念解释、禁止性行为、适用条件、过渡期安排等方面对“逃生条款”进行细化、量化，避免逃生条款过于“单薄”。1. 订立背景-加强“公平”：逃生条款应当另起新条，避免一句话带过。在逃生条款条约下，逃生条款的达成背景可做简单描述，比如：“甲方系新开商城、甲方租金较同城同类商城价位高【*%】、双方租赁期限长达【*年】、乙方的品牌优势大、品牌方入驻将对商场后期招商产生引流赋能的效果等等。”该背景陈述的方式，将“合同解除触发条件-逃生条款”的公平性与合理性进行书面载明，方便日后裁判者、仲裁员能快速识别合同的订立背景，方便非本专业的人员快速理解“逃生条款”的始末与功能，也为符合公平原则提供一定书面依据。2. 细化数额：“逃生条款”往往与零售额、销售额挂钩，草拟时需注意明确前述金额是税前还是税后金额、写明各月度营业额的起止期间。同时需要注意的是，大多数商场的业务为面向消费者的零售服务，因此是否要在条款中排除“商务大单”、怎样的大单属于商务大单、销售额的认定以商场pos机收到的款项为准，还是以柜台pos机上传的数字为准、预售模式的金额是否能计算入内、未来的退货是否扣减等等，都需要事先详细约定，避免行权时双方焦灼难下。同时在有可能的情况下，建议阐明触发逃生“数额”的条件和计算方式，阐述该“数额”的计算过程与合理性，为后续争议解决提供直接可用的触发金额，减少法院/仲裁院自由裁量的不确定性。3. 注意概念界定的统一性：条款内的销售额等概念应当前后保持一致；同时，如果已经明确店铺的营业类型，也需要保持条款内销售额的计算范围与店铺类型（零售/批发）保持一致。避免条款内计算金额的依据不统一。具体举例：如店铺为约定为“零售店铺”，则“逃生条款”内不宜将销售额约定为包含“批发、大宗交易”的数额；如“销售额”包含商场折扣支持金额，则逃生条款内的计算数额也需要明确包含商场折扣支持金额。4. 禁止性行为：逃生条款并非新事物，商场方和品牌方在多年商战中早已寻到多种破解招数，因此，建议对逃生条款进行禁止性约定。该禁止性约定旨在排除任何一方的不当干预。建议使用“举例+兜底条款”的形式进行约定，尤其需要明确排除周期性异常交易（比如商场方的恶意购买行为）。异常交易的常见情形为商场方指使人员购买品牌方的商品以达到冲销售额、规避逃生条款的目的。这类情况通常难以取证，故建议采取以下两种方式进行排除：（1）周期性异常交易在数据上反应明显，可以将销售金额的数据连续性进行要求，如约定连续6个月每月不足【*元】，可以改为：“连续【6】[2]个月中累计3个月不足【*元】。”（2）对于商场“托”商场工作人员及其家人或友商和关联公司员工等向店铺购买商品以规避逃生条款触发数额的情况，建议对此类“异常交易”进行细化、约定推定情形：“如1）【2】日内有超过【3】名疑似商场委托的雇员（包括但不限于身着工作服、下单时表示非自愿购买等）进行购买；或2）已有2名（含本数）以上购买者，有证据证明其系商场/公司委托其购买。符合1）或2）任一情形则推定商场进行恶意购买，则推定当月销售金额低于【*元】（笔者注：【*元】为逃生条款触发数额）。”5. 法律后果约定：笔者持逃生条款系“约定解除”的观点，建议在进行逃生条款的拟定时需要写明合同解除的法律后果，即，如果触发逃生条款、双方合同终止，该情况下应当约定清楚如何结算——该解除条件是无须承担任何后果的还是仍然需要一定赔偿的、装修费是否返还、水电费物业费结算方式、已经满足但尚未发放抵扣的返利/租金优惠是否受影响、租赁保证金的返还（注意租赁保证金用于抵扣水、电、物业、违约罚金的顺序问题）。如果合同本身约定了解除后果，还需避免“逃生条款”的触发后果与合同的解除后果相矛盾、如有矛盾需约定优先条款。6. 过渡期安排：在实操过程中，由于店铺的装潢拆除、商品的撤场都需要时间，但该过渡期同样存在人员、租金与水电开销、甚至影响商场客流，因此建议尽量限时撤场、限时结算，并加入罚金以敦促各方履行撤场义务，避免拖延撤场、商场方不配合而造成不必要的损失与款项争议。反向制约的可能利好品牌方的逃生条款或与之相对的利好商场方的“末位淘汰条款”均为强势方的止损条款，但在弱势方对后续发展有信心的情况下，弱势方也可以考虑进行“未来对赌”。在品牌方加入逃生条款的前提下、商场方可约定“如品牌方销售额连续【6】个月高于【一定数额】，则逃生条款自动解除”。也可在商场对品牌方设置“业绩末位淘汰”约定之时，反向约定：“如连续【6】个月营业额达到【一定数额】，则“业绩末位淘汰”条款约定自动终止或商场给予品牌方【一定数额】的奖励/补贴。该反向制约设置看似较为理想化，但在实际谈判中，尤其是逃生条款未能如愿“细化量化”的情况下，反向制约便为调节未来权益提供可能性。结语“逃生条款”的设置目的旨在调节商场方与品牌方的权利得失，在条款有效的前提下，更应当重视对该条款的拟定与谈判，不同谈判地位下采用不同的修改、细化策略，尽量保证“逃生”能真正地发挥其止损作用。注释：[1] 该约定为“在合同期限内，若被告连续6个月实际销售额低于当期年保底期间保底销售额/12个月计算所得金额，原告有权单方面终止本合同，且不承担任何违约责任。”[2] 文中【】内的内容需根据实际情况调整，文中仅作举例。',\n",
       " '近日，为落实《反电信网络诈骗法》、《互联网信息服务管理办法》等法律法规要求，工信部正式发布《关于开展移动互联网应用程序备案工作的通知》（以下简称“备案通知”），明确要求APP及小程序等移动互联网应用程序，也应当参照互联网网站办理信息服务备案（俗称的ICP备案）。《备案通知》规定，新上线的必须先备案再上线，存量整改期限截至2024年3月31日。随后，微信公众平台等陆续发布了备案细则/指引。结合最新法律法规、ISP及分发平台政策，参考类似项目经验，汇业黄春林律师团队梳理APP及小程序备案相关的20个实务问题如下，仅供参考。1. 哪些APP及小程序属于提供互联网信息服务？参照互联网网站ICP备案实践，几乎所有的APP及小程序都可能提供互联网信息服务（互联网协会说，除非不联网），因此建议都去办理备案。符合以下类型之一的，尤其需要：（1）使用了80或8080端口的；（2）提供信息推送、报表分析、即时通讯、新闻资讯、知识问答、论坛社区、游戏娱乐、评论跟帖、网络直播、电子商务、会员服务、活动报名、信息检索、网络音视频、生活服务、软件下载等服务的。2. 什么情况属于在境内提供？满足下列条件之一的，属于在境内提供：（1）ISP在中国境内（不含港澳台）；（2）在中国境内的应用分发平台（应用商店及小程序平台）上架，或者在国际应用分发平台的中国区上架。3. 仅在内部使用的APP或小程序需要办理备案吗？参照之前互联网网站ICP备案实践，只要符合前述第1、2点情形的，都需要。4. 未在公开的应用商店上架的APP，由谁代办ICP备案？ISP。5. 外国企业是否可以在中国办理APP及小程序备案？外国企业（未在国内注册）可以在境内应用商店发布APP或注册小程序。但是，参照之前互联网网站ICP备案实践，未在中国登记的外国企业不能办理ICP备案，除非是向市监局申请《外国（地区）企业常驻代表机构登记证》的代表处。6. 备案负责人是否可以是外籍人士？通常由谁担任？是否必须内部员工？预留的联系电话有什么用？有什么法律责任？主体负责人和备案负责人可以是外籍人士，但可能需要人脸核验。主体负责人通常为企业法定代表人，备案负责人通常为APP、小程序所在BU的负责人。备案时无需提供劳动合同。主体负责人和备案负责人均需预留手机号，两个手机号不能是同一个，该手机号必须保持畅通，通管局后续可能会拨打电话核验，且接电话人必须了解备案的APP或小程序的基本情况。后续有违法违规情况或其他监管措施的，通管局也可能会通过该电话联系企业。具体法律责任视情况而定。7. 开发者、运营者，域名注册者，用户协议及隐私政策披露主体，收款主体，谁是APP主办者？是否需要满足264号文的一致性要求？APP主办者通常是在应用分发平台、小程序平台登记的开发者。目前还不清楚是否可以由开发者以外的其他主体办理ICP备案。目前，《备案通知》仅要求APP及小程序内的域名、IP的ICP备案满足264号文的一致性要求，暂未扩大到APP及小程序备案。后续视各地通管局要求而定。但是，APP开发者、备案主体、协议披露主体及收款主体等不一致的，可能面临其他法律风险。8. APP及小程序备案主体与其内使用的域名、IP备案主体必须一致吗？可以不一致。例如APP或小程序使用了部分供应商的服务、插件等情况。9. 存量APP备案期间，是否影响APP或小程序的正常访问？暂不影响。10. 一个实体可以备案多个APP、小程序和网站吗？有最高限制吗？可以备案多个。暂无限制。11. 网站、APP的IOS版本、Android版本、微信小程序、百度小程序、支付宝小程序等需要分别办理ICP备案吗？目前需要分别办理。但是，属于同一个实体的，同一个备案号，不同的序列号，即使用-1、-2……-N等序列号区分。12. APP及小程序新增备案的，是否会触发264号文的一致性核验？2018年1月1日之前备案的部分老网站，可能存在域名主体和备案主体不一致的情况。根据之前互联网网站ICP备案要求，一旦有变更备案的，可能会触发264号文的一致性核验机制。APP及小程序新增备案是否会触发核验机制，需个案评估。13. 哪些APP及小程序办理备案需要前置审批？新闻、出版、教育、药品器械、游戏、互联网金融等。14. APP及小程序备案名称、类目选择有什么影响？名称不合规的，或者名称与主体不关联的，存在被通管局驳回的较大风险。类目选择可能会诱发其他准入资质合规风险，例如教育、游戏等类目。15. 如何在APP及小程序内展示/设置备案号？应当在APP及小程序的“显著位置”标明其备案编号，包括首屏/主屏底部、设置、我的、介绍等的显著位置，同时应当链接至工信部的备案系统网址。16. 什么情况下需要办理APP及小程序备案变更？ISP、证照、负责人、联系方式等变更的，需要办理变更备案。应当在30日内办理变更。未在规定时间履行备案变更手续，可以由通管局并处1万元罚款。17. APP及小程序备案是否存在有效期吗？没有特殊情况，一直有效。18. 未依法完成APP及小程序备案的有什么后果？《反电信网络诈骗法》无面向主办者未履行备案的法律责任。《互联网信息服务管理办法》规定，未履行备案手续的，由通管局责令限期改正；拒不改正的，责令关闭。未依法标注备案编号的，由通管局责令改正，处5000元以上5万元以下的罚款。根据部分应用商店、小程序平台公告，未在规定时间内完成备案的，会下架APP或小程序。19. APP及小程序办理了ICP备案，还需要办理ICP许可证？ICP备案≠ICP许可证。APP及小程序是否需要办理ICP、EDI等增值电信业务许可证的，视具体业务模式及属地通管局政策而定。20. 到底有多少个备案要搞？他们不互通吗？还不算各种的安全审查、安全评估、检测、测评、目录、年报、审计、自查等，光是备案的话，反正工信、网信、公安、市监等口子都有对应的备案，各地政策还有差异，教育、金融等行业主管部门也有相应的备案，应用分发平台和小程序平台还在努力地“夯实平台责任”……不知道未来还会不会增加……不知道他们是否互通……不知道……',\n",
       " '股权并购股权并购系指并购方以通过与目标企业的股东签订股权转让协议的方式或者认购目标企业增资的方式，成为目标企业股东，进而达到参与、控制目标企业，进入某一产业或扩大某一产业市场占有率的资本交易模式。在当下市场经济蓬勃发展、资本市场活跃的背景下，在招商引资、去产能化、供给侧改革、混和所有制推进的过程中，股权并购也变得越来越繁复。从并购主体来看，民营公司企业间的并购、国有公司企业间的并购、跨国公司企业间的并购均呈不断上升的态势。繁复的交易必然会产生各种各样的风险，但最大的风险莫过于股权转让协议的无效，如陈发树并购红塔集团股份一样，因合同无效而导致并购方案折戟沉沙。为了避免股权交易无效的风险，以下相关法律法规并购方必须参考！一、有限责任股东的优先购买权有限责任公司的股东之间可以自由转让其持有的股份，但向股东以外的人转让股份应当征求其他股东的意见，其他股东享有优先购买权。实践中，因其他股东主张优先购买权而导致股权转让协议无效，继而收购失败的案例并不少见。因此，别让股东的优先权绊住了并购前进的脚步。《中华人民共和国公司法》第七十一条规定：股东向股东以外的人转让股权，应当经其他股东过半数同意。股东应就其股权转让事项书面通知其他股东征求同意，其他股东自接到书面通知之日起满三十日未答复的，视为同意转让。其他股东半数以上不同意转让的，不同意的股东应当购买该转让的股权；不购买的，视为同意转让。经股东同意转让的股权，在同等条件下，其他股东有优先购买权。两个以上股东主张行使优先购买权的，协商确定各自的购买比例；协商不成的，按照转让时各自的出资比例行使优先购买权。公司章程对股权转让另有规定的，从其规定。第七十二条规定：人民法院依照法律规定的强制执行程序转让股东的股权时，应当通知公司及全体股东，其他股东在同等条件下有优先购买权。其他股东自人民法院通知之日起满二十日不行使优先购买权的，视为放弃优先购买权。适用《公司法》七十一条和七十二条的规定，我们应当注意三点：其一，股东之间转让股份不受其他股东优先权限制；其二，人民法院依强制程序转让和股东自行对外转让，优先权期限不同，前者是20天，后者是30天；其三，股东可以通过公司章程对优先权的行使条件做具体的约定，只要约定的内容不违反法律规定股东就应当遵守。股东的优先权，充分体现了有限责任公司人和性的特点，合同自由原则，亦与共有人的优先权制度有相通之处。在并购目标公司时，一定要依法履行相应的告知义务，莫要让优先权影响收购协议的效力。二、股权回购的限制有限责任公司和股份有限公司均禁止公司回购股权，因为公司是以资产为限对其债务承担责任，资本恒定原则和资产不受非法转移，是公司能够承担相应责任的基本要求。公司回购股权必然会导致公司的资产流入股东个人名下，从而使债权人的风险增大，这显然对债权人不公平。但是也有特殊的情形，即公司可以回购股东的股权。所以通过回购股东股权来安排股权交易的进程，或以回购股权达到控股的目的，增加其他股东的持股份额，实现并购目的，在一定条件下也是可行的。1.有限责任公司股权回购制度《中华人民共和国公司法》第七十四条规定：有下列情形之一的，对股东会该项决议投反对票的股东可以请求公司按照合理的价格收购其股权：（一）公司连续五年不向股东分配利润，而公司该五年连续盈利，并且符合本法规定的分配利润条件的；（二）公司合并、分立、转让主要财产的；（三）公司章程规定的营业期限届满或者章程规定的其他解散事由出现，股东会会议通过决议修改章程使公司存续的。自股东会会议决议通过之日起六十日内，股东与公司不能达成股权收购协议的，股东可以自股东会会议决议通过之日起九十日内向人民法院提起诉讼。异议股东要求公司回购其股权的前提是：已经形成股东会决议。其在股东会上表达的意见与股东会决议不一致时，异议股东可以采取诉讼途径主张自己的权利。很明显本条是为了保障小股东的重大利益不被侵犯、避免公司陷入僵局而设置，通过立法以公权利对私权利形成制约，以平衡各投资人的利益，保障公司的正常经营，维护社会经济的有序发展。2.股份公司或上市公司的股权回购制度《中华人民共和国公司法》第一百四十二条规定：公司不得收购本公司股份。但是，有下列情形之一的除外：（一）减少公司注册资本；（二）与持有本公司股份的其他公司合并；（三）将股份奖励给本公司职工；（四）股东因对股东大会作出的公司合并、分立决议持异议，要求公司收购其股份的。公司因前款第（一）项至第（三）项的原因收购本公司股份的，应当经股东大会决议；公司依照前款规定收购本公司股份后，属于第（一）项情形的，应当自收购之日起十日内注销；属于第（二）项、第（四）项情形的，应当在六个月内转让或者注销；公司依照第一款第（三）项规定收购的本公司股份，不得超过本公司已发行股份总额的百分之五；用于收购的资金应当从公司的税后利润中支出；所收购的股份应当在一年内转让给职工。公司不得接受本公司的股票作为质押权的标的。从一百四十二条与七十四条内容的对比中可以看出：股份有限公司可以回购股权的情况比较多，但是资本恒定的原则仍然没有太多的突破，只是给融资交易和公司更多的股权处置便利。以本公司的股票作为质押权标的也被限制，因为在实现质押权时必然涉及股权注销登记，也就是说股权质押合同履行结果要通过减少注册资本，注销部分股权才能实现，这必然导致公司的资产发生了不正当的贬损。股权并购中可以应用公司回购的方式预先清理小股东的股权，但是要掌握正确的方法，不可以让回购成为并购的负累。三、股份有限公司的股份转让应当在交易场所或按照国务院的规定方式进行《中华人民共和国公司法》第一百三十八条规定：股东转让其股份，应当在依法设立的证券交易场所进行或者按照国务院规定的其他方式进行。第一百三十九条规定：记名股票，由股东以背书方式或者法律、行政法规规定的其他方式转让；转让后由公司将受让人的姓名或者名称及住所记载于股东名册。股东大会召开前二十日内或者公司决定分配股利的基准日前五日内，不得进行前款规定的股东名册的变更登记。但是，法律对上市公司股东名册变更登记另有规定的，从其规定。第一百四十条规定：无记名股票的转让，由股东将该股票交付给受让人后即发生转让的效力。第一百四十四条规定：上市公司的股票，依照有关法律、行政法规及证券交易所交易规则上市交易。由此可见，股份有限公司可分为上市公司和非上市公司，非上市公司的股东转让股份或者上市公司的股东转让股票相对来说很容易，一般不受其他股东的优先权制约。这充分显示了股份有限公司的资合性。但为了规制公司股份的有序流通，保障股权交易和证券类金融市场合理发展，又要保障公司的经营不受股份变动的影响，国家设立了相应的交易机构和一系列的交易流程及模式。脱离了国家设立的交易场所或流程的交易形式不受法律的保护。四、股份有限公司发起人转让股份的限制《中华人民共和国公司法》第一百四十一条规定：发起人持有的本公司股份，自公司成立之日起一年内不得转让。公司公开发行股份前已发行的股份，自公司股票在证券交易所上市交易之日起一年内不得转让。公司董事、监事、高级管理人员应当向公司申报所持有的本公司的股份及其变动情况，在任职期间每年转让的股份不得超过其所持有本公司股份总数的百分之二十五；所持本公司股份自公司股票上市交易之日起一年内不得转让。上述人员离职后半年内，不得转让其所持有的本公司股份。公司章程可以对公司董事、监事、高级管理人员转让其所持有的本公司股份作出其他限制性规定。股份公司公众性比较强，公司的经营方向、资源、策略或主要资金来源，有赖于发起人、董事、监事、高级管理人员的勤勉尽责。这些人员都是能对公司的经营产生重大影响的人员，如任其转让公司的股权，容易引发公司的动荡、导致公众投资人的利益受损、公司管理混乱、投资计划不能执行、经营目标难以实现。对其转让股份的行为进行制约，这是主要投资人或重要管理人员应当对其他投资人和社会承担的一份责任。所以在受让发起人、董事、监事、高级管理人员股权时，应当设定好合同条款，并及时公布相应信息，不能违反不得转让的强制性规定。如果公司章程中有更多排斥转让的条款，应当预先通过内部程序修改章程的规定。五、国有股权的转让应当经国有资产监督管理机构决定，全部转让或转让致使国家不再拥有控股地位的，报本级人民政府批准。市场经济改革的初期，很多人利用自己国有企业或政府的领导地位，将国有资产低价转让给个人，谋取私利，损害国家利益。所以国有股权的转让执行复杂而严格的审批程序。《企业国有资产监督管理暂行条例》第二十三条规定：国有资产监督管理机构决定其所出资企业的国有股权转让。其中，转让全部国有股权或者转让部分国有股权致使国家不再拥有控股地位的，报本级人民政府批准。《企业国有产权转让管理暂行办法失效/废止》第十一条规定：企业国有产权转让应当做好可行性研究，按照内部决策程序进行审议，并形成书面决议。国有独资企业的产权转让，应当由总经理办公会议审议。国有独资公司的产权转让，应当由董事会审议；没有设立董事会的，由总经理办公会议审议。涉及职工合法权益的，应当听取转让标的企业职工代表大会的意见，对职工安置等事项应当经职工代表大会讨论通过。第十二条规定：按照本办法规定的批准程序，企业国有产权转让事项经批准或者决定后，转让方应当组织转让标的企业按照有关规定开展清产核资，根据清产核资结果编制资产负债表和资产移交清册，并委托会计师事务所实施全面审计（包括按照国家有关规定对转让标的企业法定代表人的离任审计）。资产损失的认定与核销，应当按照国家有关规定办理。转让所出资企业国有产权导致转让方不再拥有控股地位的，由同级国有资产监督管理机构组织进行清产核资，并委托社会中介机构开展相关业务。社会中介机构应当依法独立、公正地执行业务。企业和个人不得干预社会中介机构的正常执业行为。第十三条规定：在清产核资和审计的基础上，转让方应当委托具有相关资质的资产评估机构依照国家有关规定进行资产评估。评估报告经核准或者备案后，作为确定企业国有产权转让价格的参考依据。在产权交易过程中，当交易价格低于评估结果的90%时，应当暂停交易，在获得相关产权转让批准机构同意后方可继续进行。第二十五条规定：国有资产监督管理机构决定所出资企业的国有产权转让。其中，转让企业国有产权致使国家不再拥有控股地位的，应当报本级人民政府批准。第二十六条规定：所出资企业决定其子企业的国有产权转让。其中，重要子企业的重大国有产权转让事项，应当报同级国有资产监督管理机构会签财政部门后批准。其中，涉及政府社会公共管理审批事项的，需预先报经政府有关部门审批。第二十七条规定：转让企业国有产权涉及上市公司国有股性质变化或者实际控制权转移的，应当同时遵守国家法律、行政法规和相关监管部门的规定。从上述法规规定来看，国有股权转让：一是要有公司内部审批流程；二是要经国有资产监督管理机构批准；三是如果转让涉及控股权，应当由人民政府审批；四是在定价时应当参以独立的中介机构出具的评估报告为准；五是交易价格低于评估结果的90%时应当再行审批。这样以审批源头和履行结果两头堵、加之第三方机构控制中间环节的方式限定了国有股权的任意交易，控制了国有资产的流失。但同时也使国有资本在交易中失去很多机会。作为并购方，应当抓住机会，安排好流程，设计好方案，不失掉每一个细节，让并购方案切实可行。六、上市公司中的国有股权质押限制用股权质押融资，是很多股东为了解决公司的财务困难而普遍采用的办法。一旦不能按期偿还债务，则应当将质押的股权过户给债权人，所以股权质押的结果几乎等同于股权转让，鉴于上市公司中的国有股的股权持有人往往也是公司，而上市公司的股份可以在二级市场进行交易和流通，所以财政部专门就此出台了相应的文件。《财政部关于上市公司国有股质押有关问题的通知》规定：一、国有股东授权代表单位将其持有的国有股用于银行贷款和发行企业债券质押，应当遵守《中华人民共和国公司法》、《中华人民共和国担保法失效/废止》及有关国有股权管理等法律法规的规定，并制定严格的内部管理制度和责任追究制度。二、公司发起人持有的国有股，在法律限制转让期限内不得用于质押。三、国有股东授权代表单位持有的国有股只限于为本单位及其全资或控股子公司提供质押。四、国有股东授权代表单位用于质押的国有股数量不得超过其所持该上市公司国有股总额的５０％。五、国有股东授权代表单位以国有股进行质押，必须事先进行充分的可行性论证，明确资金用途，制订还款计划，并经董事会（不设董事会的由总经理办公会）审议决定。由此我们应当明确：国有股的质押其实只能用于银行贷款和发行企业债券，不能用于其他的融资模式；国有股的质押应当遵循公司法、担保法、国有有关部门对上市公司管理的相关制度；国有股的质押只能为本单位、全资或控股子公司；国有股质押不能超出所持上市公司的国有股总额的50%；国有股的质押应当充分论证，明确资金用途、还款计划，并经董事会或总经理办公会审定。七、涉外股权转让的限制《企业国有产权转让管理暂行办法失效/废止》第十六条规定：受让方为外国及我国香港特别行政区、澳门特别行政区、台湾地区的法人、自然人或者其他组织的，受让企业国有产权应当符合国务院公布的《指导外商投资方向规定》及其他有关规定。《外商投资企业投资者股权变更的若干规定失效/废止》第三条规定：企业投资者股权变更应遵守中国有关法律、法规，并按照本规定经审批机关批准和登记机关变更登记。未经审批机关批准的股权变更无效。第四条规定：企业投资者股权变更必须符合中国法律、法规对投资者资格的规定和产业政策要求。依照《外商投资产业指导目录失效/废止》，不允许外商独资经营的产业，股权变更不得导致外国投资者持有企业的全部股权；因股权变更而使用企业变成外资企业的，还必须符合《中华人民共和国外资企业法实施细则失效/废止》（以下简称《外资细则》）所规定的设立外资企业的条件。需由国有资产占控股或主导地位的产业，股权变更不得导致外国投资者或非中国国有企业占控股或主导地位。第五条规定：除非外方投资者向中国投资者转让其全部股权，企业投资者股权变更不得导致外方投资者的投资比例低于企业注册资本的２５％。因此，股权转让中的一方为外资企业或外国企业的，应当遵循《指导外商投资方向的规定》，首先要考虑该产业是否符合该规定，如果投资方向不符，则不能转让。另外外资企业包括依照中国法律在中国境内设立的中外合资企业、中外合作企业、外资企业等。']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_contents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e9d0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tokens(contents):\n",
    "    ret = []\n",
    "    for content in contents:\n",
    "        if content is not None:\n",
    "            ret.append(tokenizer.encode(content))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71024f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1747ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('tokens.json'):\n",
    "    all_tokens = convert2tokens(all_contents)\n",
    "    with open('tokens.json','w') as f:\n",
    "        json.dump(all_tokens,f)\n",
    "else:\n",
    "    with open('tokens.json','r') as f:\n",
    "        all_tokens = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03db779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "058d3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b5ae851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch(tokens,batch_size,maxlength):\n",
    "    ret = []\n",
    "    idxs = list(range(len(tokens)))\n",
    "    random.shuffle(idxs)\n",
    "    for _idx in idxs[:batch_size]:\n",
    "        arr = tokens[_idx]\n",
    "        t = 0\n",
    "        while t + maxlength < len(arr):\n",
    "            ret.append(arr[t:t+maxlength])\n",
    "            t += maxlength\n",
    "    return ret  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a1f55b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,inputs,tokenizer,device):\n",
    "    ids = tokenizer.encode(inputs)\n",
    "    print(ids)\n",
    "    y = torch.LongTensor([ids])\n",
    "    y = y.to(device)\n",
    "    print('yyyy shape',y.shape)\n",
    "    for _ in range(10):\n",
    "        logits = model(y)\n",
    "        ### logits B,T,vocab_size\n",
    "        logits = logits[:,-1,:]\n",
    "        ### logits B,T,vocab_size\n",
    "        predicts = logits.argmax(dim=-1,keepdim=True) # B,1\n",
    "        y = torch.cat((y,predicts),dim=-1)\n",
    "    print(y.shape)\n",
    "    for b in range(y.shape[0]):\n",
    "        print(tokenizer.decode(list(y[b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e10e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e25ffebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "input_dim = 64\n",
    "head_size = 4\n",
    "hidden_dim = input_dim // head_size\n",
    "output_vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b67af9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "812ac4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_3298/618891274.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gpt.load_state_dict(torch.load('simple_model_state_dict.pth'))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('simple_model_state_dict.pth'):\n",
    "    gpt = GPT(n,input_dim,head_size,hidden_dim,output_vocab_size)\n",
    "else:\n",
    "    gpt = GPT(n,input_dim,head_size,hidden_dim,output_vocab_size)\n",
    "    gpt.load_state_dict(torch.load('simple_model_state_dict.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c273af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1045604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(gpt.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d3f2ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    elif torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(f\"当前设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cf0597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gpt,res):\n",
    "    gpt.to(device)\n",
    "    for _ in range(100):\n",
    "        gpt.train()\n",
    "        y = get_random_batch(res,2,1024)\n",
    "        if y and y[0]:\n",
    "            y = torch.LongTensor(y)\n",
    "            y = y.to(device)\n",
    "            y_inputs = y[:,:-1]\n",
    "            y_targets = y[:,1:]\n",
    "            logits = gpt(y_inputs)\n",
    "            B,T = y_targets.shape\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), y_targets.reshape(-1))\n",
    "            print(loss)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        gpt.eval()\n",
    "        predict(gpt,'律师',tokenizer,device)\n",
    "        torch.save(gpt.state_dict(), 'simple_model_state_dict.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487acea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "060567b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4001, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "[36181, 233, 30585, 230]\n",
      "yyyy shape torch.Size([1, 4])\n",
      "torch.Size([1, 14])\n",
      "律师����������\n",
      "tensor(7.3379, device='mps:0', grad_fn=<NllLossBackward0>)\n",
      "[36181, 233, 30585, 230]\n",
      "yyyy shape torch.Size([1, 4])\n",
      "torch.Size([1, 14])\n",
      "律师����������\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(gpt, res)\u001b[0m\n\u001b[1;32m     12\u001b[0m B,T \u001b[38;5;241m=\u001b[39m y_targets\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), y_targets\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    520\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    707\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    624\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    628\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/_tensor_str.py:357\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/_tensor_str.py:145\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(gpt,all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40f7a625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9927e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e699eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
