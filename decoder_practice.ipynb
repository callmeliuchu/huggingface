{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15040e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b687f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9663e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional,Tuple,List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9808970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88e79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba197464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774437ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVCache():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.key_cache :List[torch.Tensor] = []\n",
    "        self.value_cache :List[torch.Tensor] = []\n",
    "    \n",
    "    \n",
    "    def num_items(self) -> int:\n",
    "        if len(self.key_cache) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.key_cache[0].shape[-2]\n",
    "    \n",
    "    def update(self,key_states:torch.Tensor,value_states:torch.Tensor,\n",
    "              layer_idx:int) -> Tuple[torch.Tensor,torch.Tensor]:\n",
    "        \n",
    "        if len(self.key_cache) <= layer_idx:\n",
    "            self.key_cache.append(key_states)\n",
    "            self.value_cache.append(value_states)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.key_cache[layer_idx] = torch.cat(\n",
    "             [\n",
    "                 self.key_cache[layer_idx],\n",
    "                 key_states\n",
    "             ],dim=-2)\n",
    "            self.value_cache[layer_idx] = torch.cat(\n",
    "            [\n",
    "                self.value_cache[layer_idx],\n",
    "                value_states\n",
    "            ],dim=-2)\n",
    "        return self.key_cache[layer_idx],self.value_cache[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b11005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 key_cache shape: torch.Size([2, 3, 4]), value_cache shape: torch.Size([2, 3, 4])\n",
      "Layer 0 key_cache shape: torch.Size([2, 6, 4]), value_cache shape: torch.Size([2, 6, 4])\n",
      "Layer 1 key_cache shape: torch.Size([2, 3, 4]), value_cache shape: torch.Size([2, 3, 4])\n",
      "Number of items in cache: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 初始化 KVCache 实例\n",
    "kv_cache = KVCache()\n",
    "\n",
    "# 创建两个新的张量，假设每个张量的形状为 (2, 3, 4)\n",
    "key_tensor = torch.randn(2, 3, 4)\n",
    "value_tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "# 更新第一个层的缓存\n",
    "key_cache, value_cache = kv_cache.update(key_tensor, value_tensor, 0)\n",
    "\n",
    "# 打印更新后的缓存\n",
    "print(f\"Layer 0 key_cache shape: {key_cache.shape}, value_cache shape: {value_cache.shape}\")\n",
    "\n",
    "# 创建另一个张量，形状也为 (2, 3, 4)\n",
    "new_key_tensor = torch.randn(2, 3, 4)\n",
    "new_value_tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "# 更新第一个层（索引为0），将新张量拼接到原缓存上\n",
    "key_cache, value_cache = kv_cache.update(new_key_tensor, new_value_tensor, 0)\n",
    "\n",
    "# 打印更新后的缓存\n",
    "print(f\"Layer 0 key_cache shape: {key_cache.shape}, value_cache shape: {value_cache.shape}\")\n",
    "\n",
    "# 创建第二个层（索引为1）的新张量\n",
    "key_tensor_layer_1 = torch.randn(2, 3, 4)\n",
    "value_tensor_layer_1 = torch.randn(2, 3, 4)\n",
    "\n",
    "# 更新第二个层的缓存\n",
    "key_cache, value_cache = kv_cache.update(key_tensor_layer_1, value_tensor_layer_1, 1)\n",
    "\n",
    "# 打印第二个层的缓存\n",
    "print(f\"Layer 1 key_cache shape: {key_cache.shape}, value_cache shape: {value_cache.shape}\")\n",
    "\n",
    "# 查看缓存的条目数\n",
    "print(f\"Number of items in cache: {kv_cache.num_items()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f271f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaConfig():\n",
    "    \"\"\"\n",
    "    Configuration class that stores all the hyperparameters needed for the Gemma model.\n",
    "    This includes things like model size (hidden_size), number of layers, attention heads, etc.\n",
    "    Think of it as a recipe card that defines how big and complex the model should be.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        intermediate_size,\n",
    "        num_hidden_layers,\n",
    "        num_attention_heads,\n",
    "        num_key_value_heads,\n",
    "        head_dim=256,\n",
    "        max_position_embeddings=8192,\n",
    "        rms_norm_eps=1e-6,\n",
    "        rope_theta=10000.0,\n",
    "        attention_bias=False,\n",
    "        attention_dropout=0.0,\n",
    "        pad_token_id=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.rms_norm_eps = rms_norm_eps\n",
    "        self.rope_theta = rope_theta\n",
    "        self.attention_bias = attention_bias\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.pad_token_id = pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d8c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PaliGemmaConfig():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vision_config=None,\n",
    "        text_config=None,\n",
    "        ignore_index=-100,\n",
    "        image_token_index=256000,\n",
    "        vocab_size=257152,\n",
    "        projection_dim=2048,\n",
    "        hidden_size=2048,\n",
    "        pad_token_id=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.image_token_index = image_token_index\n",
    "        self.vocab_size = vocab_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vision_config = vision_config\n",
    "        self.is_encoder_decoder = False\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        self.vision_config = VisionConfig(**vision_config)\n",
    "        self.text_config = text_config\n",
    "\n",
    "        self.text_config = GemmaConfig(**text_config, pad_token_id=pad_token_id)\n",
    "        self.vocab_size = self.text_config.vocab_size\n",
    "\n",
    "        self.text_config.num_image_tokens = (self.vision_config.image_size // self.vision_config.patch_size) ** 2\n",
    "        self.vision_config.projection_dim = projection_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f807562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaRMSNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim: int,eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.zeros(dim))\n",
    "    \n",
    "    def _norm(self,x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1,keepdim=True)+self.eps)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output = self._norm(x.float())\n",
    "        output = output * (1.0 + self.weight.float())\n",
    "        \n",
    "        return output.type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c86a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x:\n",
      "tensor([[[-0.4246, -0.7982, -0.8357,  0.1792],\n",
      "         [ 0.6600, -0.3522, -0.7154, -0.3926]],\n",
      "\n",
      "        [[-0.1582,  0.5388,  0.2481, -0.0237],\n",
      "         [-0.0523, -0.7688, -1.4402, -0.6932]]])\n",
      "Output after RMSNorm:\n",
      "tensor([[[-0.6826, -1.2831, -1.3434,  0.2881],\n",
      "         [ 1.1923, -0.6363, -1.2925, -0.7092]],\n",
      "\n",
      "        [[-0.5149,  1.7540,  0.8076, -0.0773],\n",
      "         [-0.0589, -0.8665, -1.6233, -0.7814]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 初始化 GemmaRMSNorm\n",
    "dim = 4  # 输入张量的特征维度\n",
    "eps = 1e-6\n",
    "rms_norm = GemmaRMSNorm(dim, eps)\n",
    "\n",
    "# 创建一个输入张量，形状为 (batch_size, dim)\n",
    "x = torch.randn(2,2, dim)  # batch_size = 2, dim = 4\n",
    "\n",
    "# 计算归一化后的输出\n",
    "output = rms_norm(x)\n",
    "\n",
    "# 打印输出结果\n",
    "print(\"Input x:\")\n",
    "print(x)\n",
    "print(\"Output after RMSNorm:\")\n",
    "print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a95311df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaRotaryEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim,max_position_embeddings=2048,\n",
    "                base=10000,device=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        \n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0,self.dim,2,dtype=torch.int64).float()/self.dim))\n",
    "        \n",
    "        self.register_buffer('inv_freq',tensor=inv_freq,persistent=False)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self,x,position_ids,seq_len=None):\n",
    "        ## position_ids  B,seq_len\n",
    "        self.inv_freq.to(x.device)\n",
    "        \n",
    "        # seq_len\n",
    "#         self.inv_freq[None,:,None].float() 1,seq_len,1\n",
    "        inv_freq_expand = self.inv_freq[None,:,None].float().expand(\n",
    "          position_ids.shape[0],-1,1\n",
    "        )\n",
    "        # B,seq_len,1 \n",
    "        \n",
    "        position_ids_expanded = position_ids[:,None,:].float()\n",
    "        ## B,1,seq_len\n",
    "        \n",
    "        device_type = x.device.type\n",
    "        device_type = device_type if isinstance(device_type,str) and device_type != \"mps\" else \"cpu\"\n",
    "        \n",
    "        with torch.autocast(device_type=device_type,enabled=False):\n",
    "            \n",
    "            t = (inv_freq_expand.float() @ position_ids_expanded.float())\n",
    "            # B,seq_len,1  @ B, 1,seq_len\n",
    "            freqs = t.transpose(1,2)\n",
    "            # B, seq_len,seq_len\n",
    "            \n",
    "            emb = torch.cat((freqs,freqs),dim=-1)\n",
    "            \n",
    "            print('embedd....',emb.shape,emb)\n",
    "            \n",
    "            cos = emb.cos()\n",
    "            sin = emb.sin()\n",
    "        \n",
    "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7498a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos shape torch.Size([2, 4])\n",
      "pos tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]])\n",
      "embedd.... torch.Size([2, 4, 8]) tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03, 1.0000e+00,\n",
      "          1.0000e-01, 1.0000e-02, 1.0000e-03],\n",
      "         [2.0000e+00, 2.0000e-01, 2.0000e-02, 2.0000e-03, 2.0000e+00,\n",
      "          2.0000e-01, 2.0000e-02, 2.0000e-03],\n",
      "         [3.0000e+00, 3.0000e-01, 3.0000e-02, 3.0000e-03, 3.0000e+00,\n",
      "          3.0000e-01, 3.0000e-02, 3.0000e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03, 1.0000e+00,\n",
      "          1.0000e-01, 1.0000e-02, 1.0000e-03],\n",
      "         [2.0000e+00, 2.0000e-01, 2.0000e-02, 2.0000e-03, 2.0000e+00,\n",
      "          2.0000e-01, 2.0000e-02, 2.0000e-03],\n",
      "         [3.0000e+00, 3.0000e-01, 3.0000e-02, 3.0000e-03, 3.0000e+00,\n",
      "          3.0000e-01, 3.0000e-02, 3.0000e-03]]])\n",
      "Cosine encoding:\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.5403,  0.9950,  0.9999,  1.0000,  0.5403,  0.9950,  0.9999,\n",
      "           1.0000],\n",
      "         [-0.4161,  0.9801,  0.9998,  1.0000, -0.4161,  0.9801,  0.9998,\n",
      "           1.0000],\n",
      "         [-0.9900,  0.9553,  0.9996,  1.0000, -0.9900,  0.9553,  0.9996,\n",
      "           1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.5403,  0.9950,  0.9999,  1.0000,  0.5403,  0.9950,  0.9999,\n",
      "           1.0000],\n",
      "         [-0.4161,  0.9801,  0.9998,  1.0000, -0.4161,  0.9801,  0.9998,\n",
      "           1.0000],\n",
      "         [-0.9900,  0.9553,  0.9996,  1.0000, -0.9900,  0.9553,  0.9996,\n",
      "           1.0000]]])\n",
      "Sine encoding:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0998, 0.0100, 0.0010, 0.8415, 0.0998, 0.0100, 0.0010],\n",
      "         [0.9093, 0.1987, 0.0200, 0.0020, 0.9093, 0.1987, 0.0200, 0.0020],\n",
      "         [0.1411, 0.2955, 0.0300, 0.0030, 0.1411, 0.2955, 0.0300, 0.0030]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0998, 0.0100, 0.0010, 0.8415, 0.0998, 0.0100, 0.0010],\n",
      "         [0.9093, 0.1987, 0.0200, 0.0020, 0.9093, 0.1987, 0.0200, 0.0020],\n",
      "         [0.1411, 0.2955, 0.0300, 0.0030, 0.1411, 0.2955, 0.0300, 0.0030]]])\n"
     ]
    }
   ],
   "source": [
    "# 初始化 GemmaRotaryEmbedding\n",
    "dim = 8  # 嵌入的维度\n",
    "embedding_layer = GemmaRotaryEmbedding(dim)\n",
    "\n",
    "# 创建一个输入张量，形状为 (batch_size, seq_len, dim)\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "x = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "# 创建位置ID，形状为 (batch_size, seq_len)\n",
    "position_ids = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "print('pos shape',position_ids.shape)\n",
    "print('pos',position_ids)\n",
    "\n",
    "# 计算旋转位置编码\n",
    "cos, sin = embedding_layer(x, position_ids)\n",
    "\n",
    "# 打印输出结果\n",
    "print(\"Cosine encoding:\")\n",
    "print(cos)\n",
    "print(\"Sine encoding:\")\n",
    "print(sin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95679943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    x1 = x[...,:x.shape[-1]//2]\n",
    "    x2 = x[...,x.shape[-1]//2:]\n",
    "    return torch.cat((-x2,x1),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "354f1808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -3.,  -4.,   1.,   2.],\n",
      "         [ -7.,  -8.,   5.,   6.],\n",
      "         [-11., -12.,   9.,  10.]],\n",
      "\n",
      "        [[-15., -16.,  13.,  14.],\n",
      "         [-19., -20.,  17.,  18.],\n",
      "         [-23., -24.,  21.,  22.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1., 2., 3., 4.],\n",
    "                   [5., 6., 7., 8.],\n",
    "                   [9., 10., 11., 12.]],\n",
    "\n",
    "                  [[13., 14., 15., 16.],\n",
    "                   [17., 18., 19., 20.],\n",
    "                   [21., 22., 23., 24.]]])\n",
    "\n",
    "output = rotate_half(x)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3391eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_pos_emb(q,k,cos,sin,unsqueeze_dim=1):\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    \n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f860c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_embed shape: torch.Size([2, 1, 5, 8])\n",
      "k_embed shape: torch.Size([2, 1, 5, 8])\n",
      "q_embed: tensor([[[[ 2.2672, -1.2059,  1.1212, -1.8954, -0.6763,  0.5578, -1.0251,\n",
      "            3.3326],\n",
      "          [ 0.1687,  1.0473,  0.1882, -0.2636,  0.5831, -0.3073, -0.9306,\n",
      "            1.1093],\n",
      "          [-0.0251, -2.3684, -0.1824,  1.7625,  2.9609,  0.5655, -0.1282,\n",
      "            0.8968],\n",
      "          [-0.6032,  0.0208, -0.5212,  0.5081,  0.2427, -0.7860, -2.0760,\n",
      "            0.0394],\n",
      "          [ 0.4414,  1.2566,  1.1808, -0.7668,  0.0767, -0.0609,  1.3863,\n",
      "           -1.8431]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6425,  1.4354, -0.4998, -1.7827,  0.0269, -0.4905,  0.7460,\n",
      "            0.5805],\n",
      "          [ 0.0751,  2.4062,  1.3051,  0.8908,  0.8581,  1.7343, -0.3459,\n",
      "            0.3036],\n",
      "          [ 0.6975,  4.6343,  0.7887, -1.8581,  1.8242, -1.2034,  0.9783,\n",
      "            1.1471],\n",
      "          [ 0.1794, -0.2345,  1.5733,  0.3319, -0.1704, -1.3123, -0.4432,\n",
      "           -0.3902],\n",
      "          [-0.1505, -1.5761, -1.2177, -0.0479,  0.4411, -1.8645, -2.6372,\n",
      "            3.3012]]]])\n",
      "k_embed: tensor([[[[-0.6009,  0.5430, -3.7261, -1.4401,  0.3075,  0.1382,  2.6003,\n",
      "            2.6753],\n",
      "          [-1.2686,  0.5070,  0.2705, -1.3318, -0.6247, -0.0609, -0.6474,\n",
      "           -3.6944],\n",
      "          [ 0.1470, -0.3513, -0.1528, -0.3097,  1.9084, -0.4162,  0.0232,\n",
      "            0.2084],\n",
      "          [-0.4623,  0.5587, -0.0066, -2.9713, -0.4979,  0.4198,  0.3223,\n",
      "           -0.4167],\n",
      "          [ 1.7112,  0.0814, -1.7407,  0.3797, -1.3809, -0.3945, -0.7894,\n",
      "            0.9014]]],\n",
      "\n",
      "\n",
      "        [[[-1.4502, -1.8804, -0.2284,  0.2021, -0.6649,  0.0093,  0.1982,\n",
      "           -0.4161],\n",
      "          [ 0.0507,  2.9520, -0.7390, -0.7693,  0.3221, -1.1109, -0.3088,\n",
      "           -0.2804],\n",
      "          [-0.5258, -1.2146, -0.1945, -0.5382,  0.3276, -0.0678, -0.2509,\n",
      "           -0.7643],\n",
      "          [-0.5641, -4.8533, -0.0319,  0.0803, -0.6133,  0.4385,  0.0773,\n",
      "            0.1478],\n",
      "          [-0.5307, -3.0590,  1.2036,  0.2280,  0.3913, -0.1598,  3.2210,\n",
      "            0.4109]]]])\n"
     ]
    }
   ],
   "source": [
    "# 模拟数据\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "dim = 8\n",
    "\n",
    "# 随机生成查询和键张量\n",
    "q = torch.randn(batch_size, 1,seq_len, dim)\n",
    "k = torch.randn(batch_size, 1,seq_len, dim)\n",
    "\n",
    "# 旋转位置编码的余弦和正弦值\n",
    "# 这里我们假设 dim 为 8，所以下面 dim // 2 = 4\n",
    "cos = torch.randn(batch_size,seq_len, dim)\n",
    "sin = torch.randn(batch_size,seq_len, dim)\n",
    "\n",
    "# 使用 apply_rotary_pos_emb 函数\n",
    "q_embed, k_embed = apply_rotary_pos_emb(q, k, cos, sin)\n",
    "\n",
    "# 打印结果\n",
    "print(\"q_embed shape:\", q_embed.shape)\n",
    "print(\"k_embed shape:\", k_embed.shape)\n",
    "\n",
    "# 查看 q_embed 和 k_embed 的具体值\n",
    "print(\"q_embed:\", q_embed)\n",
    "print(\"k_embed:\", k_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4ede9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,config):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.intermediate_size = config.intermediate_size\n",
    "        self.gate_proj = nn.Linear(self.hidden_size,\n",
    "                                  self.intermediate_size,\n",
    "                                  bias=False)\n",
    "        self.up_proj = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            self.intermediate_size,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.down_proj = nn.Linear(\n",
    "            self.intermediate_size,\n",
    "            self.hidden_size,\n",
    "            bias=False\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.down_proj(nn.functional.gelu(self.gate_proj(x),\n",
    "                                                approximate='tanh')*self.up_proj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddd70a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 模拟一个配置对象\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.hidden_size = 512\n",
    "        self.intermediate_size = 1024\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# 创建 GemmaMLP 模型\n",
    "model = GemmaMLP(config)\n",
    "\n",
    "# 随机输入数据\n",
    "x = torch.randn(2, 10, config.hidden_size)  # batch_size=2, seq_len=10, hidden_size=512\n",
    "\n",
    "# 前向传播\n",
    "output = model(x)\n",
    "print(output.shape)  # 应该是 (2, 10, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24c4d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(hidden_states: torch.Tensor,\n",
    "             n_rep: int) -> torch.Tensor:\n",
    "    batch,num_key_value_heads,slen,head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:,:,None,:,:].expand(\n",
    "        batch,\n",
    "        num_key_value_heads,\n",
    "        n_rep,\n",
    "        slen,\n",
    "        head_dim\n",
    "    )\n",
    "    return hidden_states.reshape(batch,num_key_value_heads*n_rep,\n",
    "                                slen,head_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "580b2e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result shape: torch.Size([2, 6, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (2, 3, 4, 5) 的随机张量，表示一个 batch size 为 2，3 个键值头，序列长度为 4，head_dim 为 5 的输入\n",
    "hidden_states = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "# 设置重复次数为 2\n",
    "n_rep = 2\n",
    "\n",
    "# 调用 repeat_kv 函数\n",
    "result = repeat_kv(hidden_states, n_rep)\n",
    "\n",
    "print(\"Result shape:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32bd309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,config: GemmaConfig, layer_idx:Optional[int]=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer_idx = layer_idx\n",
    "        \n",
    "        self.attention_dropout = config.attention_dropout\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_heads\n",
    "        self.head_dim = config.head_dim\n",
    "        self.num_key_value_heads = config.num_key_value_heads\n",
    "        self.num_key_value_groups = self.num_heads // self.num_key_value_heads\n",
    "        self.max_position_embeddings = config.max_position_embeddings\n",
    "        self.rope_theta = config.rope_theta\n",
    "        self.is_casual = True\n",
    "        \n",
    "        assert self.hidden_size % self.num_heads == 0\n",
    "        \n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim,bias=config.attention_bias)\n",
    "        self.k_proj = nn.Linear(self.hidden_size,self.num_key_value_heads*self.head_dim,bias=config.attention_bias)\n",
    "        self.v_proj = nn.Linear(self.hidden_size,self.num_key_value_heads*self.head_dim,bias=config.attention_bias)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim,self.hidden_size,bias=config.attention_bias)\n",
    "        \n",
    "        \n",
    "        self.rotary_emb = GemmaRotaryEmbedding(\n",
    "            self.head_dim,\n",
    "            max_position_embeddings=self.max_position_embeddings,\n",
    "            base=self.rope_theta\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self,hidden_states:torch.Tensor,\n",
    "               attention_mask: Optional[torch.Tensor] = None,\n",
    "               position_ids: Optional[torch.LongTensor] = None,\n",
    "               kv_cache: Optional[KVCache] = None,\n",
    "               **kwargs) -> Tuple[torch.Tensor,Optional[torch.Tensor],\n",
    "                                 Optional[Tuple[torch.Tensor]]]:\n",
    "        \n",
    "        bsz,q_len,_ = hidden_states.size()\n",
    "        query_states = self.q_proj(hidden_states)\n",
    "        key_states = self.k_proj(hidden_states)\n",
    "        value_states = self.v_proj(hidden_states)\n",
    "        \n",
    "        # [Batch_Size, Num_Heads_Q, Seq_Len, Head_Dim]\n",
    "        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        key_states = key_states.view(bsz,q_len,self.num_key_value_heads, self.head_dim).transpose(1,2)\n",
    "        value_states = value_states.view(bsz,q_len,self.num_key_value_heads, self.head_dim).transpose(1,2)\n",
    "        \n",
    "        \n",
    "        cos,sin = self.rotary_emb(value_states,position_ids,seq_len=None)\n",
    "\n",
    "        query_states, key_states = apply_rotary_pos_emb(\n",
    "            query_states,\n",
    "            key_states,\n",
    "            cos,\n",
    "            sin\n",
    "        )\n",
    "        \n",
    "        if kv_cache is not None:\n",
    "            key_states, value_states = kv_cache.update(\n",
    "             key_states,\n",
    "                value_states,\n",
    "                self.layer_idx\n",
    "            )\n",
    "        \n",
    "        key_states = repeat_kv(key_states,self.num_key_value_groups)\n",
    "        value_states = repeat_kv(value_states,self.num_key_value_groups)\n",
    "         \n",
    "        \n",
    "        attn_weights = torch.matmul(\n",
    "            query_states,\n",
    "            key_states.transpose(2,3)\n",
    "        ) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        assert attention_mask is not None\n",
    "        \n",
    "        attn_weights = attn_weights + attention_mask\n",
    "        attn_weights = nn.functional.softmax(attn_weights,dim=-1,dtype=torch.float32).to(query_states.dtype)\n",
    "\n",
    "        attn_weights = nn.functional.dropout(attn_weights,p=self.attention_dropout,training=self.training)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value_states)\n",
    "        \n",
    "        if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
    "            raise ValueError(\n",
    "                f\"`attn_output` should be of size {(bsz, self.num_heads, q_len, self.head_dim)}, but is\"\n",
    "                f\" {attn_output.size()}\"\n",
    "            )\n",
    "        \n",
    "        attn_output = attn_output.transpose(1,2).contiguous()\n",
    "        \n",
    "        attn_output = attn_output.view(bsz,q_len,-1)\n",
    "\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "        \n",
    "        return attn_output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a074626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedd.... torch.Size([2, 10, 16]) tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.0000e+00, 3.1623e-01, 1.0000e-01, 3.1623e-02, 1.0000e-02,\n",
      "          3.1623e-03, 1.0000e-03, 3.1623e-04, 1.0000e+00, 3.1623e-01,\n",
      "          1.0000e-01, 3.1623e-02, 1.0000e-02, 3.1623e-03, 1.0000e-03,\n",
      "          3.1623e-04],\n",
      "         [2.0000e+00, 6.3246e-01, 2.0000e-01, 6.3246e-02, 2.0000e-02,\n",
      "          6.3246e-03, 2.0000e-03, 6.3246e-04, 2.0000e+00, 6.3246e-01,\n",
      "          2.0000e-01, 6.3246e-02, 2.0000e-02, 6.3246e-03, 2.0000e-03,\n",
      "          6.3246e-04],\n",
      "         [3.0000e+00, 9.4868e-01, 3.0000e-01, 9.4868e-02, 3.0000e-02,\n",
      "          9.4868e-03, 3.0000e-03, 9.4868e-04, 3.0000e+00, 9.4868e-01,\n",
      "          3.0000e-01, 9.4868e-02, 3.0000e-02, 9.4868e-03, 3.0000e-03,\n",
      "          9.4868e-04],\n",
      "         [4.0000e+00, 1.2649e+00, 4.0000e-01, 1.2649e-01, 4.0000e-02,\n",
      "          1.2649e-02, 4.0000e-03, 1.2649e-03, 4.0000e+00, 1.2649e+00,\n",
      "          4.0000e-01, 1.2649e-01, 4.0000e-02, 1.2649e-02, 4.0000e-03,\n",
      "          1.2649e-03],\n",
      "         [5.0000e+00, 1.5811e+00, 5.0000e-01, 1.5811e-01, 5.0000e-02,\n",
      "          1.5811e-02, 5.0000e-03, 1.5811e-03, 5.0000e+00, 1.5811e+00,\n",
      "          5.0000e-01, 1.5811e-01, 5.0000e-02, 1.5811e-02, 5.0000e-03,\n",
      "          1.5811e-03],\n",
      "         [6.0000e+00, 1.8974e+00, 6.0000e-01, 1.8974e-01, 6.0000e-02,\n",
      "          1.8974e-02, 6.0000e-03, 1.8974e-03, 6.0000e+00, 1.8974e+00,\n",
      "          6.0000e-01, 1.8974e-01, 6.0000e-02, 1.8974e-02, 6.0000e-03,\n",
      "          1.8974e-03],\n",
      "         [7.0000e+00, 2.2136e+00, 7.0000e-01, 2.2136e-01, 7.0000e-02,\n",
      "          2.2136e-02, 7.0000e-03, 2.2136e-03, 7.0000e+00, 2.2136e+00,\n",
      "          7.0000e-01, 2.2136e-01, 7.0000e-02, 2.2136e-02, 7.0000e-03,\n",
      "          2.2136e-03],\n",
      "         [8.0000e+00, 2.5298e+00, 8.0000e-01, 2.5298e-01, 8.0000e-02,\n",
      "          2.5298e-02, 8.0000e-03, 2.5298e-03, 8.0000e+00, 2.5298e+00,\n",
      "          8.0000e-01, 2.5298e-01, 8.0000e-02, 2.5298e-02, 8.0000e-03,\n",
      "          2.5298e-03],\n",
      "         [9.0000e+00, 2.8460e+00, 9.0000e-01, 2.8460e-01, 9.0000e-02,\n",
      "          2.8461e-02, 9.0000e-03, 2.8461e-03, 9.0000e+00, 2.8460e+00,\n",
      "          9.0000e-01, 2.8460e-01, 9.0000e-02, 2.8461e-02, 9.0000e-03,\n",
      "          2.8461e-03]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [1.0000e+00, 3.1623e-01, 1.0000e-01, 3.1623e-02, 1.0000e-02,\n",
      "          3.1623e-03, 1.0000e-03, 3.1623e-04, 1.0000e+00, 3.1623e-01,\n",
      "          1.0000e-01, 3.1623e-02, 1.0000e-02, 3.1623e-03, 1.0000e-03,\n",
      "          3.1623e-04],\n",
      "         [2.0000e+00, 6.3246e-01, 2.0000e-01, 6.3246e-02, 2.0000e-02,\n",
      "          6.3246e-03, 2.0000e-03, 6.3246e-04, 2.0000e+00, 6.3246e-01,\n",
      "          2.0000e-01, 6.3246e-02, 2.0000e-02, 6.3246e-03, 2.0000e-03,\n",
      "          6.3246e-04],\n",
      "         [3.0000e+00, 9.4868e-01, 3.0000e-01, 9.4868e-02, 3.0000e-02,\n",
      "          9.4868e-03, 3.0000e-03, 9.4868e-04, 3.0000e+00, 9.4868e-01,\n",
      "          3.0000e-01, 9.4868e-02, 3.0000e-02, 9.4868e-03, 3.0000e-03,\n",
      "          9.4868e-04],\n",
      "         [4.0000e+00, 1.2649e+00, 4.0000e-01, 1.2649e-01, 4.0000e-02,\n",
      "          1.2649e-02, 4.0000e-03, 1.2649e-03, 4.0000e+00, 1.2649e+00,\n",
      "          4.0000e-01, 1.2649e-01, 4.0000e-02, 1.2649e-02, 4.0000e-03,\n",
      "          1.2649e-03],\n",
      "         [5.0000e+00, 1.5811e+00, 5.0000e-01, 1.5811e-01, 5.0000e-02,\n",
      "          1.5811e-02, 5.0000e-03, 1.5811e-03, 5.0000e+00, 1.5811e+00,\n",
      "          5.0000e-01, 1.5811e-01, 5.0000e-02, 1.5811e-02, 5.0000e-03,\n",
      "          1.5811e-03],\n",
      "         [6.0000e+00, 1.8974e+00, 6.0000e-01, 1.8974e-01, 6.0000e-02,\n",
      "          1.8974e-02, 6.0000e-03, 1.8974e-03, 6.0000e+00, 1.8974e+00,\n",
      "          6.0000e-01, 1.8974e-01, 6.0000e-02, 1.8974e-02, 6.0000e-03,\n",
      "          1.8974e-03],\n",
      "         [7.0000e+00, 2.2136e+00, 7.0000e-01, 2.2136e-01, 7.0000e-02,\n",
      "          2.2136e-02, 7.0000e-03, 2.2136e-03, 7.0000e+00, 2.2136e+00,\n",
      "          7.0000e-01, 2.2136e-01, 7.0000e-02, 2.2136e-02, 7.0000e-03,\n",
      "          2.2136e-03],\n",
      "         [8.0000e+00, 2.5298e+00, 8.0000e-01, 2.5298e-01, 8.0000e-02,\n",
      "          2.5298e-02, 8.0000e-03, 2.5298e-03, 8.0000e+00, 2.5298e+00,\n",
      "          8.0000e-01, 2.5298e-01, 8.0000e-02, 2.5298e-02, 8.0000e-03,\n",
      "          2.5298e-03],\n",
      "         [9.0000e+00, 2.8460e+00, 9.0000e-01, 2.8460e-01, 9.0000e-02,\n",
      "          2.8461e-02, 9.0000e-03, 2.8461e-03, 9.0000e+00, 2.8460e+00,\n",
      "          9.0000e-01, 2.8460e-01, 9.0000e-02, 2.8461e-02, 9.0000e-03,\n",
      "          2.8461e-03]]])\n",
      "Attention Output Shape: torch.Size([2, 10, 128])\n",
      "Attention Weights Shape: torch.Size([2, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example configuration (assuming GemmaConfig is properly defined)\n",
    "\n",
    "class Config:\n",
    "    \n",
    "    hidden_size=128\n",
    "    num_heads=8\n",
    "    head_dim=16\n",
    "    num_key_value_heads=4\n",
    "    attention_dropout=0.1\n",
    "    max_position_embeddings=512\n",
    "    rope_theta=10000.0\n",
    "    attention_bias=False\n",
    "\n",
    "\n",
    "config = Config()\n",
    "# 初始化 GemmaAttention 层\n",
    "# 初始化 GemmaAttention 层\n",
    "attention_layer = GemmaAttention(config)\n",
    "\n",
    "# 随机生成 hidden_states，形状 [batch_size=2, seq_len=10, hidden_size=128]\n",
    "hidden_states = torch.randn(2, 10, 128)\n",
    "\n",
    "# 生成 position_ids (假设序列长度为 10，batch_size 为 2)\n",
    "position_ids = torch.arange(10).unsqueeze(0).repeat(2, 1)  # 2 个批次，序列长度为 10\n",
    "\n",
    "# 生成 attention_mask，假设0表示填充，1表示有效token\n",
    "input_sequence = torch.tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "                              [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
    "attention_mask = (input_sequence != 0).unsqueeze(1).unsqueeze(2).to(torch.float)\n",
    "\n",
    "# 调用 forward 方法，传递 hidden_states、attention_mask 和 position_ids\n",
    "attn_output, attn_weights = attention_layer(hidden_states, attention_mask=attention_mask, position_ids=position_ids)\n",
    "\n",
    "# 打印输出形状\n",
    "print(\"Attention Output Shape:\", attn_output.shape)\n",
    "print(\"Attention Weights Shape:\", attn_weights.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff13b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c1252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
