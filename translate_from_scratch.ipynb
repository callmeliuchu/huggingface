{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8b767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a860a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/liuchu/.cache/huggingface/modules/datasets_modules/datasets/kde4/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac (last modified on Tue Dec 31 15:44:07 2024) since it couldn't be found locally at kde4, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset('kde4',lang1='en',lang2='zh_CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c7a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = raw_dataset['train'].train_test_split(train_size=0.9,seed=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d3aed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 125699\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 13967\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "be57c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Username:', 'zh_CN': '用户名 ：'}"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset['train'][7886]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f074089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ed935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'Helsinki-NLP/opus-mt-en-zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157241f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchu/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8f4da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-zh', vocab_size=65001, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t65000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5d7dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentence = split_dataset['train'][3]['translation']['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26a758fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_sentence = split_dataset['train'][3]['translation']['zh_CN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20593f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(en_sentence,text_target=zh_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70f32083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [26, 13932, 49644, 36, 17, 3778, 12179, 13, 39382, 1857, 15, 13, 816, 269, 6, 84, 32, 3, 471, 35, 3, 1963, 27139, 131, 26953, 7866, 3778, 6, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [453, 18437, 9470, 1401, 22, 17, 8, 35797, 3793, 673, 3300, 4993, 12, 32891, 19543, 3278, 10, 11560, 35797, 67, 1963, 2926, 1333, 131, 228, 18437, 9470, 1401, 8, 35797, 5051, 8, 10, 0]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eb676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c02d9bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁STRING▁()▁函数返回给定数字的字符串值。▁此函数与▁NUM2STRING▁函数相同▁。</s>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.convert_ids_to_tokens(inputs['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "364503cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 手动实现transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65edb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f877bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57443e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "036233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "319851a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FeedForward(5,7,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24e32da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "471808b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5a6333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f9a8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3836, -1.3330,  0.3668, -0.4173],\n",
       "        [ 0.9285, -0.2232,  0.8387, -1.5441],\n",
       "        [ 0.8393,  0.0920,  0.7285, -1.6599],\n",
       "        [ 1.5067, -0.0065, -0.2004, -1.2999],\n",
       "        [-0.7406, -0.4775,  1.7229, -0.5048]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,4)\n",
    "ln = LayerNorm(4)\n",
    "ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c99d7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.qw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,hidden_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        ## B,T,C\n",
    "        B,T,C = x.shape\n",
    "        q = self.qw(x)\n",
    "        k = self.kw(x)\n",
    "        v = self.vw(x)\n",
    "        print(q.shape,k.shape,k.T.shape)\n",
    "        att = q @ k.permute(0,2,1)\n",
    "#         att = att.masked_fill(mask, value)\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "04576096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88463ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = Attention(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "46641e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 6]) torch.Size([5, 3, 6]) torch.Size([6, 3, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "09f302b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_size):\n",
    "        super().__init__()        \n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.qw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.kw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        self.vw = nn.Linear(input_dim,head_size * hidden_dim)\n",
    "        \n",
    "    def forward(self,q,k,v,masked=False):\n",
    "        #### q ==> B,T,C\n",
    "        q = self.qw(q)\n",
    "        k = self.kw(k)\n",
    "        v = self.vw(v)\n",
    "        #### q ===> B,head_size,T,hidden_size\n",
    "        B,T,C = q.shape\n",
    "        q = q.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = k.shape\n",
    "        k = k.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,T,C = v.shape\n",
    "        v = v.reshape(B,T,self.head_size,self.hidden_size).permute(0,2,1,3)\n",
    "        B,head_size,T,hidden_size = q.shape\n",
    "        att = q @ k.permute(0,1,3,2) # B,head_size,T,T\n",
    "        if masked:\n",
    "            _,_,m,n = att.shape\n",
    "            mask = torch.ones(m,n)\n",
    "            mask = torch.tril(mask)\n",
    "            att = att.masked_fill(mask==0,float('-inf'))\n",
    "        att = F.softmax(att,dim=-1)\n",
    "        v = att @ v  # B,head_size,T,hidden_size\n",
    "        v = v.permute(0,2,1,3) # B,T,head_size,hidden_size\n",
    "        v = v.reshape(B,T,self.head_size * self.hidden_size)\n",
    "        return v       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "2bd95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "e6b61340",
   "metadata": {},
   "outputs": [],
   "source": [
    "att1 = MultiHeadAttention(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad12462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "693c4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = torch.randn(1,1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "72fcd95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2754, -1.5449,  0.9508, -0.7407],\n",
       "          [ 0.6911,  0.5579, -0.8990, -1.2444]]]])"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "35020e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " _,_,m,n = att.shape\n",
    "mask = torch.ones(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "1e999702",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tril(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "5e63ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True],\n",
       "        [False, False,  True,  True]])"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "b64e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = att.masked_fill(mask==0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "0113c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5333, 0.4667, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(att,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df863faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "7f0df0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "    \n",
    "    def forward(self,q,k,v):\n",
    "        x = q + self.mha(q,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.fd(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "608ecd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = EncoderBlock(4,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "a8d870cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "a7bf7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,head_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.ln1 = LayerNorm(input_dim)\n",
    "        self.fd = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln2 = LayerNorm(input_dim)\n",
    "        self.mha2 = MultiHeadAttention(input_dim,head_size,hidden_dim)\n",
    "        self.fd2 = FeedForward(input_dim,hidden_dim,input_dim)\n",
    "        self.ln3 = LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self,x,k,v):\n",
    "#         x,k0,v0 = self.mha.qkv(x) ### 需要masked\n",
    "        x = x + self.mha(x,k,v)\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mha2(x,k,v) ### cross attention\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.fd2(x)\n",
    "        x = self.ln3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08347ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e50db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abcd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabaeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f847430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c379827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "f1fb5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self,n,input_dim,head_size,hidden_dim,input_vocab_size,output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "           [EncoderBlock(input_dim,head_size,hidden_dim) for _ in range(n)]\n",
    "        )\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "           [DecoderBlock(input_dim,head_size,hidden_dim)   for _ in range(n)]\n",
    "        )\n",
    "        self.input_embeddings = nn.Embedding(input_vocab_size,input_dim)\n",
    "        self.output_embeddings = nn.Embedding(output_vocab_size,input_dim)\n",
    "        self.output_linear = nn.Linear(head_size * hidden_dim,output_vocab_size)\n",
    "        self.input_pos_embedding = nn.Embedding(1024,input_dim)\n",
    "        self.output_pos_embedding = nn.Embedding(1024,input_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,x,y):\n",
    "        #### x ==> B,T\n",
    "        B,T = x.shape\n",
    "        x = self.input_embeddings(x) ### B,T,C\n",
    "        x_pos = self.input_pos_embedding(torch.arange(T))\n",
    "        x = x + x_pos\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x,x,x)  ### B,head_size,T,hidden_size\n",
    "        B,T = y.shape\n",
    "        y = self.output_embeddings(y) ### B,T,C\n",
    "        y_pos = self.output_pos_embedding(torch.arange(T))\n",
    "        y = y + y_pos\n",
    "        for block in self.decoder_blocks:\n",
    "            y = block(y,x,x) ### B,head_size,T,hidden_size\n",
    "        logits = self.output_linear(y) # B,T,output_vocab_size\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "a0216483",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "input_dim = 4\n",
    "head_size = 2\n",
    "hidden_dim = input_dim // head_size\n",
    "input_vocab_size = 10\n",
    "output_vocab_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "addf8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(n,input_dim,head_size,hidden_dim,input_vocab_size,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "0385e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor([\n",
    "    [0,1,3],\n",
    "    [0,2,3]\n",
    "])\n",
    "y = torch.LongTensor([\n",
    "    [1,3,4,5],\n",
    "    [2,3,4,6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "5b3fbe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 15])"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(x,y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "8baf393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\"input\":\"In the heart of the city, there is a beautiful park where people can enjoy nature and relax after a long day of work.\",\"output\":\"在城市的中心，有一座美丽的公园，人们可以在那里享受自然，在漫长的工作日后放松身心。\"},\n",
    "    {\"input\":\"The rapid development of technology has brought about significant changes in our daily lives, making it more convenient for us to communicate and access information.\",\"output\":\"科技的快速发展给我们的日常生活带来了巨大的变化，使我们能够更方便地进行沟通和获取信息。\"},\n",
    "    {\"input\":\"Despite the challenges we face, we should always maintain an optimistic attitude towards life, believing that every problem has a solution.\",\"output\":\"尽管我们面临挑战，但我们应该始终保持对生活的乐观态度，相信每个问题都有解决方案。\"},\n",
    "    {\"input\":\"With the increasing popularity of online shopping, more and more people are choosing to purchase goods through the internet, which not only saves time but also offers a wider range of choices.\",\"output\":\"随着网上购物的日益普及，越来越多的人选择通过互联网购买商品，这不仅节省了时间，还提供了更广泛的选择。\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "a08dec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.vocab_set = set()\n",
    "        for sentence in sentences:\n",
    "            self.vocab_set.update(sentence)\n",
    "        self.vocab_set = list(self.vocab_set)\n",
    "        self.vocab_set = ['<pad>','<bos>','<eos>'] + self.vocab_set\n",
    "        self.token2id = {c:i for i,c in enumerate(self.vocab_set)}\n",
    "        self.id2token = {i:c for c,i in self.token2id.items()}\n",
    "    \n",
    "    def convert_token_to_id(self,tokens):\n",
    "        return [self.token2id.get(t,'') for t in tokens]\n",
    "    \n",
    "    def convert_id_to_token(self,ids):\n",
    "        return [self.id2token.get(i,-1) for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "4cacbf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the heart of the city, there is a beautiful park where people can enjoy nature and relax after a long day of work.',\n",
       " 'The rapid development of technology has brought about significant changes in our daily lives, making it more convenient for us to communicate and access information.',\n",
       " 'Despite the challenges we face, we should always maintain an optimistic attitude towards life, believing that every problem has a solution.',\n",
       " 'With the increasing popularity of online shopping, more and more people are choosing to purchase goods through the internet, which not only saves time but also offers a wider range of choices.']"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d['input'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "c8be92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = Tokenizer([d['input'] for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "516763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokenizer = Tokenizer([d['output'] for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "ec25d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<bos>', '<eos>', '每', '后', '更']"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.convert_id_to_token([0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "ce2831fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentences,tokenizer,max_length,is_output=False):\n",
    "    res = []\n",
    "    for sentence in sentences:\n",
    "        arr = tokenizer.convert_token_to_id(sentence)\n",
    "        if is_output:\n",
    "            arr = tokenizer.convert_token_to_id(['<bos>']) + arr + tokenizer.convert_token_to_id(['<eos>'])\n",
    "        if len(arr) > max_length:\n",
    "            arr = arr[:max_length]\n",
    "        else:\n",
    "            arr = arr + tokenizer.convert_token_to_id(['<pad>']) * (max_length - len(arr))\n",
    "        res.append(arr)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "5cafd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [d['input'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "5d2c8023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the heart of the city, there is a beautiful park where people can enjoy nature and relax after a long day of work.',\n",
       " 'The rapid development of technology has brought about significant changes in our daily lives, making it more convenient for us to communicate and access information.',\n",
       " 'Despite the challenges we face, we should always maintain an optimistic attitude towards life, believing that every problem has a solution.',\n",
       " 'With the increasing popularity of online shopping, more and more people are choosing to purchase goods through the internet, which not only saves time but also offers a wider range of choices.']"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5a1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "16fdefdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokenizer.convert_token_to_id(['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4171e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "d0ff0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = process([d['input'] for d in dataset],input_tokenizer,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "19b0961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = process([d['output'] for d in dataset],output_tokenizer,30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbf9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "d812f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "f1c8289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "98567261",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "input_dim = 64\n",
    "head_size = 4\n",
    "hidden_dim = input_dim // head_size\n",
    "input_vocab_size = len(input_tokenizer.id2token)\n",
    "output_vocab_size = len(output_tokenizer.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "5bda0862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "02119b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "9d7d0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(n,input_dim,head_size,hidden_dim,input_vocab_size,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "10c4251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30, 129])"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(x,y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "936ce308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "44ce85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(transformer.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "38fd7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "53e58b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7206, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5362, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4196, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3261, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2572, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1908, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1247, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0582, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9766, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8654, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7720, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5734, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4731, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9990, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8699, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4588, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2864, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9818, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0807, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0691, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0490, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0259, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    y_inputs = y[:,:-1]\n",
    "    y_targets = y[:,1:]\n",
    "    logits = transformer(x,y_inputs)\n",
    "    B,T = y_targets.shape\n",
    "    # 计算损失\n",
    "    loss = criterion(logits.reshape(B*T,-1), y_targets.reshape(B*T))\n",
    "    print(loss)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "8d8f7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,inputs):\n",
    "    ids = input_tokenizer.convert_token_to_id(inputs)\n",
    "    x = torch.LongTensor([ids])\n",
    "    y = torch.LongTensor([output_tokenizer.convert_token_to_id(['<bos>'])])\n",
    "    for _ in range(100):\n",
    "        logits = model(x,y)\n",
    "        ### logits B,T,vocab_size\n",
    "        logits = logits[:,-1,:]\n",
    "        ### logits B,T,vocab_size\n",
    "        predicts = logits.argmax(dim=-1,keepdim=True) # B,1\n",
    "        y = torch.cat((y,predicts),dim=-1)\n",
    "    print(y.shape)\n",
    "    for b in range(y.shape[0]):\n",
    "        for i in y[b]:\n",
    "            print(output_tokenizer.convert_id_to_token([int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "2e7d9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 101])\n",
      "['<bos>']\n",
      "['，']\n",
      "['城']\n",
      "['市']\n",
      "['的']\n",
      "['相']\n",
      "['公']\n",
      "['，']\n",
      "['能']\n",
      "['，']\n",
      "['人']\n",
      "['益']\n",
      "['的']\n",
      "['，']\n",
      "['然']\n",
      "['的']\n",
      "['，']\n",
      "['人']\n",
      "['们']\n",
      "['的']\n",
      "['日']\n",
      "['相']\n",
      "['的']\n",
      "['化']\n",
      "['，']\n",
      "['使']\n",
      "['益']\n",
      "['们']\n",
      "['，']\n",
      "['，']\n",
      "['能']\n",
      "['，']\n",
      "['的']\n",
      "['相']\n",
      "['的']\n",
      "['相']\n",
      "['终']\n",
      "['，']\n",
      "['相']\n",
      "['，']\n",
      "['，']\n",
      "['相']\n",
      "['相']\n",
      "['，']\n",
      "['人']\n",
      "['，']\n",
      "['相']\n",
      "['，']\n",
      "['的']\n",
      "['给']\n",
      "['们']\n",
      "['的']\n",
      "['信']\n",
      "['，']\n",
      "['，']\n",
      "['，']\n",
      "['越']\n",
      "['的']\n",
      "['们']\n",
      "['应']\n",
      "['，']\n",
      "['联']\n",
      "['日']\n",
      "['益']\n",
      "['丽']\n",
      "['的']\n",
      "['们']\n",
      "['益']\n",
      "['的']\n",
      "['相']\n",
      "['信']\n",
      "['，']\n",
      "['相']\n",
      "['，']\n",
      "['的']\n",
      "['面']\n",
      "['，']\n",
      "['的']\n",
      "['相']\n",
      "['，']\n",
      "['终']\n",
      "['城']\n",
      "['，']\n",
      "['，']\n",
      "['相']\n",
      "['的']\n",
      "['终']\n",
      "['保']\n",
      "['，']\n",
      "['使']\n",
      "['，']\n",
      "['，']\n",
      "['，']\n",
      "['，']\n",
      "['能']\n",
      "['们']\n",
      "['的']\n",
      "['们']\n",
      "['应']\n",
      "['，']\n",
      "['，']\n"
     ]
    }
   ],
   "source": [
    "predict(transformer,'The rapid development of technology has brought about significant changes in our daily lives, making it more convenient for us to communicate and access information.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "df1abc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "68ddc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self,n,input_dim,head_size,hidden_dim,output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "           [DecoderBlock(input_dim,head_size,hidden_dim)   for _ in range(n)]\n",
    "        )\n",
    "        self.output_embeddings = nn.Embedding(output_vocab_size,input_dim)\n",
    "        self.output_linear = nn.Linear(head_size * hidden_dim,output_vocab_size)\n",
    "        self.output_pos_embedding = nn.Embedding(1024,input_dim)\n",
    "        \n",
    "\n",
    "    def forward(self,y):\n",
    "        B,T = y.shape\n",
    "        y = self.output_embeddings(y) ### B,T,C\n",
    "        y_pos = self.output_pos_embedding(torch.arange(T))\n",
    "        y = y + y_pos\n",
    "        for block in self.decoder_blocks:\n",
    "            y = block(y,y,y) ### B,head_size,T,hidden_size\n",
    "        logits = self.output_linear(y) # B,T,output_vocab_size\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "cdc3f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['你好，世界',\n",
    "             '好奇怪',\n",
    "             '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "5fc267d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "899ab5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>',\n",
       " 1: '<bos>',\n",
       " 2: '<eos>',\n",
       " 3: '怪',\n",
       " 4: '，',\n",
       " 5: '界',\n",
       " 6: '好',\n",
       " 7: '奇',\n",
       " 8: '你',\n",
       " 9: '世'}"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "d3aef35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "input_dim = 64\n",
    "head_size = 4\n",
    "hidden_dim = input_dim // head_size\n",
    "output_vocab_size = len(tokenizer.id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "649cfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(n,input_dim,head_size,hidden_dim,output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "fd59feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(gpt.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "afacfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "37e906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentences,tokenizer,max_length):\n",
    "    res = []\n",
    "    length = []\n",
    "    for sentence in sentences:\n",
    "        arr = tokenizer.convert_token_to_id(sentence) + tokenizer.convert_token_to_id(['<eos>'])\n",
    "        length.append(len(arr))\n",
    "        if len(arr) > max_length:\n",
    "            arr = arr[:max_length]\n",
    "        else:\n",
    "            arr = arr + tokenizer.convert_token_to_id(['<pad>']) * (max_length - len(arr))\n",
    "        res.append(arr)\n",
    "    return res,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8dcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "03cceb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,lengths = process(sentences,tokenizer,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "c59d8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "e8c4e6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "afa4a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_length = torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "e5003b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4])"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "dc9f2d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True, False,  True,  True, False, False, False])"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "b3b90576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1720, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1490, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    y_inputs = y[:,:-1]\n",
    "    y_targets = y[:,1:]\n",
    "    logits = gpt(y_inputs)\n",
    "    B,T = y_targets.shape\n",
    "    # 计算损失\n",
    "#     loss = criterion(logits.reshape(B*T,-1), y_targets.reshape(B*T))\n",
    "    \n",
    "    \n",
    "    # 创建mask来标记有效位置\n",
    "    mask = torch.arange(T, device=y_targets.device)[None,:] < (batch_length-1)[:,None]  # shape: (B,T)\n",
    "    mask = mask.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "    # 只计算有效位置的loss\n",
    "    logits_flat = logits.reshape(-1, logits.size(-1))  # shape: (B*T,vocab_size) \n",
    "    targets_flat = y_targets.reshape(-1)  # shape: (B*T)\n",
    "\n",
    "    # 方法1: 使用mask选择有效位置\n",
    "    valid_logits = logits_flat[mask]  # shape: (num_valid,vocab_size)\n",
    "    valid_targets = targets_flat[mask]  # shape: (num_valid)\n",
    "    loss = criterion(valid_logits, valid_targets)\n",
    "    print(loss)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "4d8c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,inputs,tokenizer):\n",
    "    ids = tokenizer.convert_token_to_id(inputs)\n",
    "    print(ids)\n",
    "    y = torch.LongTensor([ids])\n",
    "    print('yyyy shape',y.shape)\n",
    "    for _ in range(100):\n",
    "        logits = model(y)\n",
    "        ### logits B,T,vocab_size\n",
    "        logits = logits[:,-1,:]\n",
    "        ### logits B,T,vocab_size\n",
    "        predicts = logits.argmax(dim=-1,keepdim=True) # B,1\n",
    "        y = torch.cat((y,predicts),dim=-1)\n",
    "    print(y.shape)\n",
    "    for b in range(y.shape[0]):\n",
    "        for i in y[b]:\n",
    "            print(tokenizer.convert_id_to_token([int(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "193c0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 6, 4, 9]\n",
      "yyyy shape torch.Size([1, 4])\n",
      "torch.Size([1, 104])\n",
      "['你']\n",
      "['好']\n",
      "['，']\n",
      "['世']\n",
      "['界']\n",
      "['<eos>']\n",
      "['好']\n",
      "['，']\n",
      "['世']\n",
      "['世']\n",
      "['世']\n",
      "['世']\n",
      "['界']\n",
      "['世']\n",
      "['，']\n",
      "['世']\n",
      "['界']\n",
      "['<eos>']\n",
      "['，']\n",
      "['世']\n",
      "['，']\n",
      "['世']\n",
      "['世']\n",
      "['好']\n",
      "['<eos>']\n",
      "['好']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['好']\n",
      "['，']\n",
      "['世']\n",
      "['好']\n",
      "['<eos>']\n",
      "['好']\n",
      "['<eos>']\n",
      "['世']\n",
      "['<eos>']\n",
      "['好']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['好']\n",
      "['世']\n",
      "['世']\n",
      "['世']\n",
      "['好']\n",
      "['好']\n",
      "['好']\n",
      "['<eos>']\n",
      "['好']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['好']\n",
      "['界']\n",
      "['世']\n",
      "['世']\n",
      "['世']\n",
      "['<eos>']\n",
      "['好']\n",
      "['好']\n",
      "['<eos>']\n",
      "['，']\n",
      "['世']\n",
      "['，']\n",
      "['世']\n",
      "['好']\n",
      "['好']\n",
      "['<eos>']\n",
      "['好']\n",
      "['界']\n",
      "['世']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['世']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['<eos>']\n",
      "['好']\n",
      "['，']\n",
      "['世']\n",
      "['世']\n",
      "['，']\n",
      "['世']\n",
      "['界']\n",
      "['世']\n",
      "['，']\n",
      "['界']\n",
      "['好']\n",
      "['世']\n",
      "['世']\n"
     ]
    }
   ],
   "source": [
    "predict(gpt,'你好，世',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de20524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
